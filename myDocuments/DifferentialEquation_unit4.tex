\section{UNIT4}
\clearpage

\subsection{Operators and Exponential Response}

\subsubsection{Objective}

\textbf{\color{blue}Objectives}
\begin{itemize}
\item Write {\color{blue} linear constant coefficient} differential equations
  using {\color{blue} operator} notation, that is using
  {\color{blue} linear time invariant (LTI) operators}.
\item Use {\color{blue} time-shifts } to solve LIT differential equations.
\item Solve inhomogeneous constant coefficient ODEs with exponential inputs
  using the {\color{blue} Exponential Response Formula (ERF)}.
\item Recognize when ERF {\color{blue} fails} and how to apply the {\color{blue} ERF'} and
  the {\color{blue} Generalized ERF} in these situations.
\item Apply superposition to higher order, linear {\color{blue} inhomogeneous }
  differential equations. 
\end{itemize}
\clearpage

\subsubsection{Operator Notation}

If $y_1$ and $y_2$ are two solutions to a homogeneous, linear differential equation
\begin{equation*}
  \ddot y + p\dot y + qy = 0,
\end{equation*}
Why is $c_1y_1 + c_2y_2$ a solution?\\

You know superposition for linear homogeneous differential equations.
We want an elegant proof because it will help us with more complicated problems,
including solving higher order inhomogeneous equations.\\

\paragraph{An elegant proof of superposition}
The superposition principle says exactly that if $y_1$ and $y_2$ are solution to a  linear homogeneous ODE. \\
\footnote{in fact, it can be of higher order too, In other words, you don't have to stop
with a second derivative. You could add a third derivative and fourth derivative.
As long as the form remained the same, then that implies, automatically, that $c_1 y_1 + c_2 y_2$
is a solution.}
Now the way to do that nicely is to take a little detour and talk a little bit about
{\color{blue}linear operators}.
And since we're going to be using these for the rest of the term, this is the natural place for you
to learn a little bit about what they are.
So I'm going to do it.
Ultimately, I am aimed at a proof of this statement, but there are going to be certain side
excursions I have to make.\\

The first side excursion is to write the differential equation in a different way.
So I'm going to just write its transformations.
So first, I'll simply recopy it, 
\begin{equation*}
  \ddot y + p\dot y + qy = 0. 
\end{equation*}
That's the first form. \\
The second form, I'm going to replace this by the differentiation operator $D$
\begin{equation*}
  D^2 y + pDy qy = 0, 
\end{equation*}

$D^2$ means differentiate it twice. $D$ it, and then $D$ it again.
$D$ means only have to differentiate once, so I'll write that as $p Dy$, $p$ times the derivative of $y$.\\
Now I'm going to formally factor out the $y$.
\begin{equation*}
  \left( D^2 + pD + q \right)y = 0 
\end{equation*}
So this I'm going to turn into $D^2 +  pD + q$.
Now everybody reads $D^2 +  pD + q$ times $y$ equals $0$.
But what it means is $(D^2 + pD + q)y$ means this is shorthand for
$D^2 y + pDy qy$.
I'm multiplying $q$ times $y$, but I'm not multiplying $D$ times $y$.
I'm applying $D$ to $y$. \\
And now I'll take the final step.
I'm going to view $(D^2 + pD + q)$ as a guy all by itself, a {\color{blue} linear operator}.
This is called a linear operator.
And I'm going to simply abbreviate it by the letter $L$.
And so the final version of this equation
\begin{equation*}
  Ly = 0
\end{equation*}

\clearpage
Now what's L? You could think of L as
\begin{equation*}
  L = D^2 + pD + q 
\end{equation*}

But you can think of L the way to think of it is as a black box.
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-linear_operator}
  \caption{Linear Operators}
\end{figure}

What goes into this black box? Well if this were a function box, what
would go in would be a number and what would come out would be a number.
But it's not that kind of a black box. It's an {\color{blue} operator box}.
And therefore what goes in is a function of $x$, and what comes out is another function of $x$,
the result of applying this operator to that.\\
So from this point of view, trying to solve the differential equation means what should come
out, you want to come out 0 and the question is what should you put in?
That's what it means; solving differential equations in an {\color{blue} inverse problem}.
The easy thing is to put in a function and see what comes out.
You just calculate. The hard thing is to ask.
You say, I want such and such a thing to come out, for example, $0$.
What should I put in? That's the difficult question.
And that's what we're spending the term answering.\\

Now the key thing about this is that this is a linear operator
and what that means is that it behaves in a certain way with respect to functions.
The easiest way to say it is, I like to make two laws of it,
\begin{align*}
  L(u _1 + u _2 ) &= L(u_1) + L(u_2)
  \text{ Where } u _1 \text{ and } u _2 \text{ a function of } x \\
  L(c u) &= c L(u) \text{ Where } c \text{ is a any constant. } 
\end{align*}
These are the two laws of linearity.
An operator is linear if it satisfies these two laws.
Now for example, the differentiation operator is such an operator; D is linear.
Why?
\begin{align*}
  (u _1 + u _2)' &= u' _1 + u' _2 \\
  (cu)' &= c u' 
\end{align*}

All that was a prelude to proving this simple theorem, the superposition principle.
So finally, what's the proof?
Well, proof of the superposition principle, if you believe that the operator is linear,
in other words, the ODE is $L$.
$L$ is $D^2 +  pD +  q$. So the ODE is $Ly = 0$.
And what am I being asked to prove?
I'm being asked to prove that if $y _1$ and $y _2$ are solutions,
\begin{align*}
  L(c_1 y _1 + c_2 y_2 \footnotemark) &= L(c_1 y _1) + L(c _2 y _2) \\
                                      &= c _1 L(y _1) + c _2 L(y _2) \\
                                      &= c _1 0 + c _2 0 = 0                                        
\end{align*}
\footnotetext{
  $c_1 y _1 + c_2 y_2$ called a linear combination.
  This expression is called a linear combination of $y_1$ and $y_2$.
  It means that particular sum with constant coefficients.
}
I'm trying to prove that this is $0$.
Well, what is $L(y _1)$?
At this point, I use the fact that $y_1$ is a solution.
Because it's a solution, this is $0$. That's what it means to solve that differential equation.
It means when you apply the linear operator $L$ to the function, you get $0$.
In the same, way $y _2$ is a solution. So that's $0$. 
That's the argument.
Why it's so is because the operator, this differential equation, is expressed as a linear operator applied
to $y$ is $0$.
And the only properties that are really being used is the fact that this operator is linear.
That's the key point. $L$ is linear.
It's a linear operator.\\

\textbf{\color{blue} The operator $D$}
\begin{itemize}
\item A function takes an input number and returns another number.
\item An {\color{blue} operator} takes an input \textbf{function} and return another function. 
\end{itemize}

For example, the {\color{blue} differential operator} $\frac{d}{dt}$ takes an input function
$y(t)$ and returns $\frac{dy}{dt}$.
This operator is also called {\color{blue} $D$}.
For instance $De^{4t} = 4e^{4t}$. The operator $D$ is {\color{blue} linear} ,
which means that
\begin{equation*}
  D(f+g) = Df + Dg, \qquad D(af) = a Df
\end{equation*}

for any functions $f$ and $g$, and any number $a$. Because of this, $D$
behaves well with respect to linear combinations, namely
\begin{equation*}
  D(c_1 f_1 + \cdots + c_ n f_ n) = c_1 \,  D f_1 + \cdots + c_ n \,  Df_ n
\end{equation*}
for any numbers $c_1,\ldots ,c_ n$ and functions $f_1,\ldots ,f_ n$.

\begin{example}
  $Dt^3 = 3t^2$. 
\end{example}

\Warning You can't take this equation and substitute $t = 2$ to get $D8 = 12$.
The only way to interpret ``8'' in ``$D8$'' is as a constant function,
which of course has derivative zero: $D8 = 0$.
The point is that in order to know the function $Df(t)$ at a particular value of $t$,
say $t = a$, you need to know more than just $f(a)$;
you need to know how $f(t)$ is changing near $a$ as well.
This is characteristic of operators;
in general you have to expect to need to know the whole function $f(t)$ in order to evaluate an operator on it.

\begin{mydef}
  In general, a linear operator $L$ is any operator that satisfies
  \begin{equation*}
    L(f+g) = Lf + Lg, \qquad L(af) = a\, Lf
  \end{equation*}
  for any function $f$ and $g$, and any number $a$. 
\end{mydef}

\begin{example}
  The operator $L = D^2 + p(t)D + q(t)$ where $p(t)$ and $q(t)$ are
  any functions of $t$ is a linear operator. 
\end{example}
Why is $L$ linear? You know that $D$ is linear, and similarly, $D^2$ is linear.
To see that $L$ is linear, verify that a linear combination of linear operators is again a linear operator.

\clearpage
\subsubsection{Multiplying and adding operators}
To apply a product of two operators, apply each operator in succession.
For instance, $DDy$ means take the derivative of $y$, and then take the derivative of the result;
therefore we write $D ^2 y = \ddot{y}$.\\

To apply a sum of two operators, apply each operator to the function and add the results.
For instance,
\begin{equation*}
  (D^2 + D) y = D^2 y + D y = \ddot{y} + \dot{y}
\end{equation*}

Any number can be viewed as the ``multiply-by-the-number'' operator:
for instance, the operator $5$ transforms the function $\sin ⁡x$ into the function $5 \sin ⁡x$.\\

Similarly, we can multiply by any function of $t$, and this is also a linear operator.
For instance, the operator $t^2$ transforms the function $\sin ⁡x$ into the function $t ^22 \sin⁡ x$.

\begin{example}
  The ODE
\end{example}
\begin{equation*}
  2 \ddot{y} + 3 \dot{y} + 5 y = 0,
\end{equation*}
whose characteristic polynomial is $P(r) = 2r^2+3r+5$, can be rewritten as
\begin{align*}
  (2D^2 + 3D + 5) y &= 0\\
  P(D) y &= 0 
\end{align*}

The same argument shows that every constant-coefficient homogeneous linear ODE
\begin{equation*}
  a_ n y^{(n)} + \cdots + a_0 y = 0
\end{equation*}
can be written simply as
\begin{equation*}
  P(D) y = 0,
\end{equation*}
where $P$ is the characteristic polynomial.

\begin{exercise}
  Operator notation concept check
\end{exercise}
Consider the differential equation
\begin{equation*}
  \displaystyle  \frac{d^4x}{dt^4}+2\frac{d^2x}{dt^2}+x=0.
\end{equation*}
If we want to write the differential equation in the form
$P\left(D\right)x=0$, what is the differential operator $P\left(D\right)$?\\

The characteristic polynomial of the differential equation
\begin{equation*}
  \displaystyle  \frac{d^4x}{dt^4}+2\frac{d^2x}{dt^2}+x=0
\end{equation*}
is $P\left(r\right)=r^4+2r^2+1$, so the differential equation can be written in the form
$P\left(D\right) x = 0$, where
\begin{equation*}
  \displaystyle  P\left(D\right)=D^4+2D^2+1
\end{equation*}

\begin{exercise}
  Linear operators concept check
\end{exercise}
Which of the following differential operators are linear? Check all that apply.
\begin{enumerate}
\item $4D ^n + 3$
\item $D + t ^2$
\item $D ^2 + tD + t ^2$
\item $mD ^2 + bD + k$
\item $a_0D^ n + a_1D^{n-1} + \cdots + a_ n$
\end{enumerate}

All of these operators are linear.
In particular, every linear differential equation can be written in terms of a linear differential operator.\\

The second and third choices are linear with variable coefficients.
The first, fourth, and fifth are linear with constant coefficients.\\

We'll only have formulas for solutions when the operators involved have constant coefficients.
\clearpage

\subsubsection{Time Invariance}
In this course we'll focus on polynomial differential operators with constant coefficients,
that is operators of the form
\begin{equation*}
  \displaystyle  P\left(D\right)=a_ nD^ n+a_{n-1}D^{n-1}+\dots a_1D+a_0,
\end{equation*}

where all of the coefficients $a_k$ are numbers (as opposed to functions of $t$).
All operators of this form are linear.
In addition to being linear operators, they are also {\color{blue}time-invariant} operators, which means:
\begin{equation*}
  \text{If } x(t) \text{solves } P\left(D\right)x=f\left(t\right), \,
  \text{then } y\left(t\right)=x\left(t-t_0\right) \text{ solves }
  P\left(D\right)y=f\left(t-t_0\right)
\end{equation*}

In words, this says that ``delaying the input signal $f(t)$ by $t_0$
seconds delays the output signal $x(t)$ by $t_0$ seconds.''
If we know that $x(t)$ is a solution to $P\left(D\right)x=f\left(t\right)$,
we can solve $P\left(D\right)y=f\left(t-t_{0}\right)$ by replacing $t$ by $t - t_ 0$.
This is a useful property because gives us the solutions to many differential equations for free.

\begin{example}
  The function $x(t) = \sin (t)$ solves the differential equation
  $\dot(x) = \cos t$.  
\end{example}
What is a solution to the differential equation
\begin{equation*}
  \dot y = \cos (t +\pi /2) ?
\end{equation*}
By time-invariance, one solution is $y=\sin (t+\pi /2)$. \\
Note that
\begin{eqnarray*}
  \dot{y} &=& \cos (t + \pi / 2) \\
  \dot{y} &=& \cos t \cos \pi / 2  - \sin t \sin \pi / 2 \\
  \dot{y} &=& - \sin t 
\end{eqnarray*}

And
\begin{eqnarray*}
  y &=& \sin (t + \pi / 2) \\
  y &=& \sin t \cos  \pi / 2 + \cos t \sin  \pi / 2 \\
  y &=& \cos t 
\end{eqnarray*}

\begin{example}
  Consider the differential equation
\end{example}
\begin{equation*}
  \displaystyle  \dot{x}+x=\cos t.
\end{equation*}
Using integrating factors $e^t$
\begin{eqnarray*}
  e^t \dot{x} + e^t x &=& e^t \cos t \\
  \int (e^t x)' dt &=& \int e^t \cos t dt \footnotemark \\
  e^t x &=& \frac{e^{t}}{2} \cos t + \frac{1}{2} \sin t + c_1  \\
  x &=& \frac{1}{2} \cos t + \frac{1}{2} \sin t + c_1 e^{-t}.
\end{eqnarray*}

\footnotetext{
  $\cos t$ is a real part of $e^{it}$,
  \begin{align*}
    \int e^t \cos t dt  &= \int e^t e^{it} dt \\
                        &= \int  e^{(1 + i)t} dt \\
                        &= \frac{1}{1+i} e^{t} e^{it} + c \\
                        &= \frac{e^{t}}{2} \left( (1 - i) (\cos t + i \sin t)\right) + c \\
                        &= \frac{e^{t}}{2} \left( (1 - i) (\cos t + i \sin t)\right) + c 
  \end{align*}
  The $\mathbb{Re} \left( (1 - i) (\cos t + i \sin t)\right)$ is
  $\cos t + \sin t$.
  So,
  \begin{equation*}
    \int e^t \cos t dt = \frac{1}{2} \cos t + \frac{1}{2} \sin t + c
  \end{equation*}
}

Now suppose that we want to solve the equation $\dot{y}+y=\sin t$.
Since $\sin t=\cos \left(t-\pi /2\right)$, time invariance tells us that
\begin{align*}
  \displaystyle  y\left(t\right)
  &\displaystyle =x\left(t-\frac{\pi }{2}\right)
    =\frac12\cos \left(t-\pi /2\right) + \frac12 \sin \left(t-\pi /2\right)+c_1e^{-\left(t-\pi /2\right)} \\
  &\displaystyle =
    \frac12\sin \left(t\right) - \frac12 \cos \left(t\right)+
    \underbrace{c_1e^{\pi /2}}_{\textrm{call this }c_{2}}e^{-t} \\
  &\displaystyle =\frac12\sin \left(t\right) - \frac12 \cos \left(t\right)+c_2e^{-t}
\end{align*}

should solve $\dot{y}+y=\sin t$.
This agrees with the solution we'd get if we had used variation of parameters or integrating factors,
but we had to do almost no work to get this solution from the first.
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-LTI_function}
  \caption{LTI Function}
\end{figure}

\begin{exercise}
  LTI concept check
\end{exercise}

Which of the following differential operators are LTI operators? Check all that apply.
\begin{itemize}
\item $4D^ n + 3$
\item $D + t^2$
\item $D^2 +tD + t^2$
\item $mD^2 +bD +k$
\item $a_0D^ n + a_1D^{n-1} + \cdots + a_ n$
\end{itemize}

All of these operators are linear, and all of them that are polynomials with constant coefficients are time-invariant.
The exceptions are $tD + 2$ and $D^2 +tD + t^2$. \\
To see that $P\left(D\right)=tD + 2$ for instance is not time-invariant,
notice that the general solution to
\begin{equation*}
  \displaystyle  P\left(D\right)x=t\dot{x}+2x=t^5
\end{equation*}
on $\left(0,+\infty \right)$ is
\begin{equation*}
  \displaystyle  x\left(t\right)=\frac{1}{7}t^{5}+ct^{-2}
\end{equation*}

Now if the operator were time invariant, then
\begin{equation*}
  \displaystyle  y\left(t\right)
  =x\left(t-t_{0}\right)=\frac{1}{7}\left(t-t_0\right)^{5}+c\left(t-t_0\right)^{-2}
\end{equation*}
would solve
\begin{equation*}
  \displaystyle  t\dot{y}+2y=\left(t-t_{0}\right)^5,
\end{equation*}
for any $t_{0}>0$. However,
\begin{equation*}
  \displaystyle t\dot{y}+2y
  =\frac{2}{7}\left(t-t_{0}\right)^5+\frac{5}{7}t\left(t-t_{0}\right)^4
  +2c\left(t-t_0\right)^{-2}-2ct\left(t-t_{0}\right)^{-3}.
\end{equation*}
It should be clear from this that $t\dot{y}+2y\neq \left(t-t_{0}\right)^5$,
so the linear operator $tD + 2$ tD + 2. 
\clearpage

\subsubsection{Superposition for an inhomogeneous linear ODE}
To understand the general solution $y$ to an inhomogeneous linear ODE

\begin{equation*}
  \text {inhomogeneous equation:}
  \quad p_ n(t) \,  {\color{blue}{y^{(n)}}}  + \cdots + p_0(t) \,
  {\color{blue}{y}}  = {\color{orange}{q(t)}} ,
\end{equation*}
do the following:
\begin{enumerate}
\item List all solutions to the associated homogeneous equation
  \begin{equation*}
    \text {homogeneous equation:}
    \quad p_ n(t) \,  {\color{blue}{y^{(n)}}}  +
    \cdots + p_0(t) \,  {\color{blue}{y}}  = 0;
  \end{equation*}
\item Find (in some way) any \textbf{one} particular solution $y_p$ to the
  \textbf{inhomogeneous} ODE.
\item Add $y_p$ to all the solutions of the homogeneous ODE to get all the solutions to the inhomogeneous ODE.
\end{enumerate}

\Summary \\
\begin{equation*}
  \underset {{\color{blue}{\text {general solution}}} }{y}
  = \underset {{\color{blue}{\text {particular solution}}} }{y_ p}
  + \underset {\text {general homogeneous solution}}{y_ h}.
\end{equation*}

Why does this work? \textbf{Proof.} Let $L$ be the linear operator
$L = p_ n(t)D^ n + \dotsb + p_1(t)D+p_0(t)$.
Then the differential equations become
\begin{eqnarray*}
  \displaystyle  \text {inhomogeneous equation} \qquad Ly
  \displaystyle &=& \displaystyle q(t) \\
  \displaystyle  \text {homogeneous equation} \qquad Ly
  \displaystyle &=& \displaystyle 0   
\end{eqnarray*}
Let $y_p$ be a particular solution to the inhomogeneous equation $L(y_p)=q$.
Let $y_h$ be a homogeneous solution $L(y_h)=0$. Then
\begin{equation*}
  L(y_ p+y_ h) =q+0=q.
\end{equation*}
Suppose that $y$ is also a solution to $Ly=q$. That is
\begin{eqnarray*}
  \displaystyle  Ly \qquad \displaystyle &=& \qquad q \\
  \displaystyle  Ly_p \qquad \displaystyle &=& \qquad q.
\end{eqnarray*}
Then it follows by linearity that
\begin{equation*}
  L(y-y_ p) = L(y)-L(y_ p) = q - q = 0
\end{equation*}
Therefore $y−y_p=y_h$ is a solution to the associated homogeneous equation. In other words,
\begin{equation*}
  y=yp+yh.
\end{equation*}

{\color{blue} The result of this section is the key point of linearity in the inhomogeneous case.}
It lets us build \textbf{all} the solutions to an inhomogeneous DE out of
\textbf{one particular solution} provided that you have already solved the associated homogeneous ODE.

\paragraph{Consequence of superposition for inhomogeneous equations}
So the {\color{blue}main theorem} about solving the inhomogeneous equation.
\begin{equation*}
  \ddot{y} + p\dot{y} + q = f(x) 
\end{equation*}
I'm going to make the left hand side a linear operator $L$.
And I'm going to write the equation
\begin{equation*}
  Ly = f(x). 
\end{equation*}
And what the theorem says is that the solution has the following form.
\begin{equation*}
  \text{Solution : } y_p + y_c\footnotemark 
\end{equation*}
\footnotetext{
  $y_c$ stands for the complementary solution.\\
  The general solution of differential equation is
  \begin{equation*}
    y = y_p + c_1 y_1 + c_2 y_2 \text{, where } y_h = c_1 y_1 + c_2 y_2
  \end{equation*}
}
What is $y_p$? $p$ stands for \textbf{particular}, the most confusing word in this subject.\\

The procedure for solving this equation is composed of two steps.
First, to find complementary solution $y_c$.
solve not the equation you are given, but the reduced equation.
The second step is to find $y_p$.
$y_p$ is a particular solution to the whole equation. Yeah, but which one?
Any one. Well, if it's any one, then it's not a particular solution.
So particular means any one solution.\\


First prove the theorem
It's extremely simple if you just use the fact that $L$ is a linear operator.
We've got two things to prove.
\begin{enumerate}
\item All the $y_p + c_1 y_1 + c_2 y_2$ are solutions.\\
  You plug it into the equation and you see if it satisfies the equation.
  \begin{eqnarray*}
    L(y_p + c_1 y_1 + c_2 y_2)
    &=& \underbrace{L(y_p)}_{f(x) \text{ since particular solution} }
        + \underbrace{L(c_1 y_1 + c_2 y_2)}_{0 \text{ since homogeneous solution}} \\
    L(y_p + c_1 y_1 + c_2 y_2) &=& f(x)    
  \end{eqnarray*}
  They satisfy the whole inhomogeneous differential equation
  \begin{equation*}
    L(y) = f(x).  
  \end{equation*}

\item There are no other solutions. \\
  So, Let $u(x)$ as a solution.
  \begin{equation*}
    L(u) = f(x).
  \end{equation*}
  The $L(y_p)$ is
  \begin{equation*}
    L(y_p) = f(x). 
  \end{equation*}
  Subtract two equations
  \begin{equation*}
    L(u - y_p) = 0 
  \end{equation*}
  The homogeneous solution $L(c_1 y_1 + c_2 y_2) = 0$, 
  \begin{equation*}
    u - y_p = \tilde{c_1}y_1 + \tilde{c_1} y_1 
  \end{equation*}
  I'll put a $\tilde{ }$ on to indicate it's a particular one. 
  Therefor
  \begin{equation*}
    u  = y_p + \tilde{c_1}y_1 + \tilde{c_1} y_1 
  \end{equation*}  
\end{enumerate}
All we have to do is find to solve equations which are inhomogeneous,
all we have to do is find a particular solution.
Find one solution. It doesn't matter which one.
\clearpage

\subsubsection{Why exponential inputs?}
Our task for today is to find particular solutions.
We're talking about the second order equation with constant coefficients,
which you can think of as modeling springs or simple electrical circuits.
\begin{equation*}
  y'' + Ay' + By = f(x)
\end{equation*}
The problem is remember that to find a particular solution $y_p$. 
And the reason why we want to do that is then the general solution will be
of the form is $y$ equals that particular solution, plus the complementary solution
the general solution to the reduced equation,
\begin{equation*}
  y = y_p + c_1 y_1 + c_2 y_2. 
\end{equation*}
So all the work depends upon finding out what that $y_p$ is.
And that's what we're going to talk about. \\

But the point is not all functions that you could write on the right-hand side are equally interesting.
There's one kind, which is far more interesting or more important in the applications than all the others.
And that's the one out of which, an arbitrary function can be built out of these simple functions.
So the important function is on the right-hand side to be able to solve it when it's a simple exponential.
But if you allow me to make it a complex exponential, so here are the important right-hand sides we want.
We want to be able to do $f(x)$ when it's of the form $e^{ax}$.
in most applications, a is not a growing exponential, but a decaying exponential.
So typically, $a < 0$, but it doesn't have to be.
That's not any assumption that I'm going to make today. It's just culture.
\begin{equation*}
   f(x) = e^{ax} \text{ or , } \left\{
    \begin{array}{rl}
      \sin \omega x \\
      \cos \omega x
    \end{array} \right. 
\end{equation*}
In other words, when the right-hand side is a pure oscillation.
That's another important type of input both for electrical circuits(alternating current) or the spring systems that's a pure vibration is being. 
you're imposing a pure vibration on the spring mass dashpot system, and you want to see how it responds to that. \\

You can put them together and make these decaying oscillations.
\begin{equation*}
  f(x) =  \left\{
    \begin{array}{rl}
      e^{ax } \sin \omega x \\
      e^{ax} \cos \omega x
    \end{array} \right. 
\end{equation*}

Now, the point is all of these together are really just special cases of one general thing--
exponential if you allow the exponent not to be a real number, but to be a complex number.
So they are all special cases of
\begin{equation*}
  f(x) = e^{(a + i \omega) x}. 
\end{equation*}

If $\omega$ is $0$, then I've got $f(x) = e^{ax}$.
If $a = 0$, then I've got $\sin \omega x$ or $\cos \omega x$ separating it into its real and imaginary parts.
And if neither is $0$, I have a $e^{(a + i \omega) x}$.

But I don't want to keep writing $a + i \omega$ all the time.
So I'm going to write that simply as $e^{\alpha x}$.
And you understand that alpha is a complex number now.

\clearpage
\subsubsection{Shortcut}

\textbf{Warm-up problem: } if $r$ is a number, what is $(2D^2+3D+5) e^{rt}$?\\
\Solution First, $D e^{rt} = r e^{rt}$ and $D^2 e^{rt} = r^2 e^{rt}$ (keep applying the chain rule). Thus
\begin{align*}
  \displaystyle  (2D^2+3D+5) e^{rt}  \displaystyle &= 2 r^2 e^{rt} + 3 r e^{rt} + 5 e^{rt} \\
  \displaystyle &= (2r^2+3r+5) e^{rt}.
\end{align*}

The operator is $P(D) = 2D^2+3D+5$. Notice that $P(r) = 2r^2+3r+5$
is the characteristic polynomial. The same calculation, but with an arbitrary polynomial, proves the following general rule.

\begin{theorem}
  For any polynomial $P$ and any number $r$,
  \begin{equation*}
    {\color{blue}{P(D) e^{rt} = P(r) e^{rt}.}}
  \end{equation*}
\end{theorem}

\paragraph{Setup}
There are just a couple of basic formulas that we're going to use all the time.\\
The first is that if you apply $P(D)$ to a complex exponential or a real one-- it doesn't matter--
the answer is 
\begin{equation*}
  P(D) e^{\alpha x} = P(\alpha) e^{\alpha x}. 
\end{equation*}
The $P(\alpha)$ is now just an ordinary complex number.
So that's a basic formula.
It's called, the substitution rule, because the heart of it is you substitute for the $D$,
you substitute $\alpha$.\\

\begin{proof}
  How would I prove that?
  Well, just calculate it out.
  \begin{align*}
    \left( D^2 + AD + B\right) e^{\alpha x}
    &= D^2 e^{\alpha x} + AD e^{\alpha x} + B  e^{\alpha x} \\
    &= \alpha ^2 e^{\alpha x} + A \alpha e^{\alpha x} + B  e^{\alpha x} \\
  \end{align*}

It's obviously true for the operator $D$ and the operator $D^2$.
In other words,
\begin{equation*}
  D  e^{\alpha x} = \alpha e^{\alpha x}, \qquad D^2  e^{\alpha x} = \alpha^2 e^{\alpha x} 
\end{equation*}
And therefore, it's true for linear combinations of these as well by linearity.
So therefore, also true for $P(D)$.
\end{proof}
\clearpage
\subsubsection{Exponential response formula}
\textbf{Question:} For any polynomial $P$ and any number $r$, what is a particular solution to
\begin{equation*}
  P(D)y = e^{rt}
\end{equation*}

{\color{blue} Answer(superposition):} We have
\begin{equation*}
  P(D) {\color{blue}{e^{rt}}}  = {\color{orange}{P(r) e^{rt}}} .
\end{equation*}

This is off by a factor of $P(r)$. So multiply through by $1/P(r)$ and we can use linearity to get
\begin{equation*}
  P(D)\left(\frac{1}{P(r)}e^{rt} \right) = e^{rt}.
\end{equation*}

\textbf{\color{orange} Conclusion:} This is called the {\color{blue} Exponential Response Formula (ERF).}\\
In words, for any polynomial $P$ and any number $r$ such that $P(r) \neq 0$,
\begin{equation*}
  {\color{blue}{\frac{1}{P(r)} e^{rt}}}  \quad
  \text { is a particular solution to }
  \quad P(D) y = {\color{blue}{e^{rt}}} .
\end{equation*}

Remember, this is just one particular solution.
To get the general solution, we need to add the solution to the associated homogeneous equation.

\begin{example}
  Find the general solution to $\ddot{y} + 7\dot{y} + 12 y = {\color{blue}{-5e^{2t}}}$. 
\end{example}

\Solution\\
\begin{align*}
  \text{Characteristic polynomial:} \qquad
  &P(r) = r^2+7r+12 = (r+3)(r+4)\\
  \text{Roots:} \qquad
  & -3, -4\\
  \text{General solution to \textbf{homogeneous} equation:} \qquad
  & {\color{orange}{y_ h}}  = c_1 e^{-3t} + c_2 e^{-4t}    
\end{align*}

ERF says:
\begin{equation*}
  {\color{blue}{\frac{1}{P(2)} e^{2t}}}
  \quad \text {is a particular solution to }
  \quad P(D) y = {\color{blue}{e^{2t}}} ;
\end{equation*}
i.e.,
\begin{equation*}
  {\color{blue}{\frac{1}{30} e^{2t}}}
  \quad \text { is a particular solution to }
  \quad \ddot{y} + 7 \dot{y} + 12 y = {\color{blue}{e^{2t}}} ,
\end{equation*}
so
\begin{equation*}
  \underset {{\color{blue}{ \text {call this } y_ p}} }{-\frac{1}{6} e^{2t}}
  \quad \textrm{ is a particular solution to }
  \quad \ddot{y} + 7 \dot{y} + 12 y = {\color{blue}{-5e^{2t}}} .
\end{equation*}

General solution to inhomogeneous equation:
\begin{align*}
  \displaystyle y \displaystyle &= {\color{blue}{y_ p}}  + {\color{orange}{y_ h}} \\
  \displaystyle &= -\frac{1}{6} e^{2t} + c_1 e^{-3t} + c_2 e^{-4t}.
\end{align*}
\clearpage
\subsubsection{ERF and complex roots}

\begin{example}
  Use ERF to find a particular solution to $\ddot x + x = e^{2it}$.
\end{example}

\Solution In operator notation, this differential equation can be written as
\begin{equation*}
  (D^2+1)y = e^{2it}.
\end{equation*}
By the ERF, a particular solution is given by
\begin{equation*}
  y_ p = \frac{e^{rt}}{r^2+1} = \frac{e^{2it}}{(2i)^2+1} = \frac{-1}{3}e^{2it}.
\end{equation*}

\begin{exercise}
  Practice problem 1
\end{exercise}
Use ERF to find a particular solution to
\begin{equation*}
  (D^2+1)y = e^{-t}.
\end{equation*}
By the ERF, a particular solution is
\begin{equation*}
  y _p = \frac{e^{-t}}{r^2 + 1} = \frac{e^{-t}}{(-1)^2 + 1} = \frac{e^{-t}}{2} 
\end{equation*}

\begin{exercise}
  Practice problem 2
\end{exercise}
Use ERF and superposition to find a particular solution to
\begin{equation*}
  (D^2+1)y = e^{-t} - 3e^{2it} .
\end{equation*}
By superposition
\begin{eqnarray*}
  (D^2+1)(c_1 y_1 + c_2 y_2) &=& e^{-t} - 3e^{2it} \\
  (D^2+1)(c_1 y_1) + (D^2+1)(c_2 y_2) &=& e^{-t} - 3e^{2it} \\
  c_1 (D^2+1)(y_1) + c_2(D^2+1)(y_2) &=& e^{-t} - 3e^{2it}
\end{eqnarray*}
By ERF, the particular solution of $ c_1 (D^2+1)(y_1) = e^{-t}$ is
\begin{equation*}
  y_{1p} = \frac{e^{-t}}{r^2 + 1} = \frac{e^{-t}}{(-1)^2 + 1} = \frac{e^{-t}}{2}. 
\end{equation*}
By ERF, the particular solution of $ c_2 (D^2+1)(y_2) = -3 e^{-2it}$ is
\begin{equation*}
  -3 y_{2p} = -3 \left(\frac{e^{2it}}{r^2 + 1} \right)
  = -3 \left(\frac{e^{2it}}{(2i)^2 + 1} \right)
  = -3 \left(\frac{-1}{3} e^{2it} \right) = e^{2it}. 
\end{equation*}
The particular solution is
\begin{equation*}
  y _p = y_{1p} + y_{2p} =  \frac{e^{-t}}{2}  + e^{2it}. 
\end{equation*}

\clearpage
\subsubsection{The generalized exponential response formula}

\begin{exercise}
  When the ERF fails
\end{exercise}
For which of the following functions $q\left(t\right)=e^{at}$ does the differential equation
$\ddot{x}+x = q(t)$ \textbf{not} have a solution of the form $Ae^{at}$?

\begin{itemize}
\item $e^t$
\item $e^{-t}$
\item $e^{it}$
\item $e^{-it}$
\item $e^{2it}$
\item $e^{3t}$
\item $1$
\end{itemize}
The characteristic polynomial is $P(r) = r^2+1$.
This polynomial is zero when $r=\pm i$.
Thus we can not apply the Exponential Response Formula to find a solution of the form
$e^{at}$ is when $a=\pm i$.\\

The existence and uniqueness theorem says that
\begin{equation*}
  P(D) y = e^{rt}
\end{equation*}
should have a solution even if $P(r) = 0$(when ERF does not apply). Let's start with the one case:\\
{\color{blue} ERF'} Suppose that $P$ is a polynomial and $P(r _0) = 0$, but
$P'(r _0) \neq 0$ for some number $r_0$. Then
\begin{equation*}
  \boxed {{\color{blue}{x_ p=\frac{1}{P'(r_0)} t e^{r_0t}}}  \
    quad \text { is a particular solution to }\quad P(D) x = {\color{blue}{e^{r_0t}}} .}
\end{equation*}

\begin{proof}
  We want to solve $P(D)y = e^{r_0t}$. We know that
  \begin{equation*}
    P(D)e^{r_0t} = P(r_0)e^{r_0t},
  \end{equation*}
  for all $r$. However, since $P(r_0)$ is zero, we cannot divide by it.\\
  Instead, let us look at what happens near this point $r_0$ and differentiate with respect to $r$.
  \begin{equation*}
    \displaystyle  \displaystyle \frac{\partial }{\partial r}\left(P(D) e^{rt} \right)
    \displaystyle = \displaystyle  \frac{\partial }{\partial r}\left(P(r) e^{rt} \right)
    = P'(r)e^{rt} + P(r)te^{rt}.
  \end{equation*}
  We need to take the derivative of the left hand side. Recall that
  $\frac{\partial }{\partial r}\frac{\partial }{\partial t}
  = \frac{\partial }{\partial t}\frac{\partial }{\partial r}$.
  In this context, this means the same thing as
  \begin{equation*}
    \frac{\partial }{\partial r}D =
    D\frac{\partial }{\partial r} \qquad \left(D = \frac{d}{dt} \right).
  \end{equation*}
  Hence
  \begin{equation*}
    \frac{\partial }{\partial r}P(D) = P(D)\frac{\partial }{\partial r}
  \end{equation*}
  by linearity. \\
  The left hand side becomes.
  \begin{align*}
    \displaystyle  \displaystyle \frac{\partial }{\partial r}\left(P(D) e^{rt} \right)
    \displaystyle &= \displaystyle  P(D) \left( \frac{\partial }{\partial r} e^{rt}\right) \\
    \displaystyle &= \displaystyle  P(D) \left( te^{rt}\right)
  \end{align*}
  Let $r\rightarrow r_0$. Therefore since $P(r _0) = 0$
  \begin{align*}
    \displaystyle  P(D) \left( te^{r_0t}\right)
    \displaystyle &= \displaystyle  P'(r_0)e^{r_0t} + P(r_0)te^{r_0t} \\
    \displaystyle &= \displaystyle  P'(r_0)e^{r_0t}
  \end{align*}
  If $P'(r _0) \neq 0$. then we can divide through by $P'(r _0)$
  \begin{equation*}
    P(D) \left( \frac{te^{r_0t}}{P'(r_0)}\right) = e^{r_0t},
  \end{equation*}
  and $\displaystyle y_ p = \frac{te^{r_0t}}{P'(r_0)}$ is a particular solution to $P(D)y = e^{r_0t}$
\end{proof}

\begin{example}
  Find a particular solution to $\ddot{x} -4x = e^{-2t}$
\end{example}

\Solution The characteristic polynomial is $P(r) = r^2 - 4$, thus $P(-2) = 0$, But
$P'(2) = 2(-2) = -4 \ne 0$. Therefore this is a cae where we can apply ERF'.
which gives us a particular solution
\begin{equation*}
  x_ p = \frac{te^{rt}}{P'(r)} = \frac{te^{-2t}}{-4}.
\end{equation*}

\begin{example}
  Solve the system $\ddot{x} + x = e^{it}$ with initial conditions $x(0)=1$ and $\dot{x}(0) = 0$.
\end{example}
The characteristic polynomial of the differential equation $\ddot{x} + x = e^{it}$ is $P(r) = r^2 + 1$
, with roots $\pm i$.
Since $i$ is a root of the characteristic polynomial, the {\color{blue}Generalized ERF} tells
us to find the smallest integer $s$ for which $P(s)(i) \ne 0$.
In this case, $P'(r) = 2r$, so $P'(i) = 2i$, which is not zero, so $s = 1$.
The Generalized ERF tells us that
\begin{equation*}
  \displaystyle  x_ p\left(t\right)=\frac{1}{P^{\prime }\left(i\right)}t^{1}e^{it}
  =\frac{1}{2i}te^{it}
\end{equation*}
is particular solution to the inhomogeneous ODE.
Since $\frac{1}{i} = e^{-i \pi/2}$ \footnote{
  \begin{align*}
    \frac{1}{i} &= \frac{1}{i} \cdot \frac{i}{i} \\
    \frac{1}{i} &= -i \\
    \frac{1}{i} &= \cos (-\pi / 2) + i \sin (-\pi / 2) \\
    \frac{1}{i} &= e^{i \frac{-\pi}{2}}
                  \quad \text{where } e^{i \theta} = \cos \theta + i \sin theta     
  \end{align*}
}
, we can write $x _P$ as
\begin{equation*}
  \displaystyle  x_ p\left(t\right)=\frac{1}{2}te^{it-i\pi /2}.
\end{equation*}
Since the characteristic polynomial has roots $\pm i$, we know that the pair
\begin{equation*}
  \displaystyle  e^{it},e^{-it}
\end{equation*}
form a basis for the space of solutions to the homogeneous equation
$\ddot{x}+x=0$.
Hence, the general solution to the inhomogeneous equation
$\ddot{x}+x=e^{it}$ is
\begin{equation*}
  \displaystyle  x\left(t\right)
  =\underbrace{c_{1}e^{it}+c_{2}e^{-it}}_{\text {general solution to homogeneousODE}}
  +\underbrace{\frac{1}{2}te^{it-i\pi /2}.}_{{\color{orange}{\text {particular solution}}} }
\end{equation*}
Now we just need to solve for the constants $c_1$ and $c_2$
from the initial conditions initial conditions $x(0)=1$ and $\dot{x}(0) = 0$.
We see that
\begin{equation*}
  \displaystyle  x\left(0\right)=1=c_{1}+c_{2},
\end{equation*}
so $c _2 = 1 - c _1$, and we can write $x(t)$ as
\begin{equation*}
  \displaystyle  x\left(t\right)
  =c_{1}e^{it}+\left(1-c_{1}\right)e^{-it}+\frac{1}{2}te^{it-i\pi /2}.
\end{equation*}
We see that
\begin{equation*}
  \displaystyle  \dot{x}\left(t\right)
  =ic_{1}e^{it}-i\left(1-c_{1}\right)e^{-it}+\frac{1}{2}e^{it-i\pi /2}+\frac{1}{2}te^{it},
\end{equation*}
so
\begin{align*}
  \displaystyle  \dot{x}\left(0\right)
  \displaystyle &=ic_{1}-i\left(1-c_{1}\right)+\frac{1}{2}e^{-i\pi /2}\\
  \displaystyle &=ic_{1}-i\left(1-c_{1}\right)-\frac{i}{2}.
\end{align*}

Using the initial condition $\dot{x}(0) = 0$ and solving for $c_1$ we see that $c_1 = 3/4$.
Substituting this into the equation $c_2 = 1 - c_1$, we see that $c_2 = 1/4$.
Thus the solution to the system $\ddot{x} + x = e^{it}$ with initial conditions $x(0)=1$ and $\dot{x}(0) = 0$
is
\begin{equation*}
  \displaystyle  x\left(t\right)=
  \frac{3}{4}e^{it}+\frac{1}{4}e^{-it}+\frac{1}{2}te^{it-i\pi /2}.
\end{equation*}


\textbf{Generalized exponential response formula.} if $P$ is a polynomial and $r_0$ is a number
such that
\begin{equation*}
  P(r_0) = P'(r_0) = \dotsb = P^{(m-1)}(r_0) = 0 \qquad P^{(m)}(r_0) \neq 0,
\end{equation*}
then
\begin{equation*}
  P(D)\left( t^ me^{r_0t} \right) = P^{(m)}(r_0)e^{r_0t}
\end{equation*}
and
\begin{equation*}
  \boxed {{\color{blue}{y_ p=\frac{1}{P^{(m)}(r_0)} t^ m e^{r_0t}}}
    \quad \text { is a particular solution to }
    \quad P(D) y = {\color{blue}{e^{r_0t}}} .}
\end{equation*}

\begin{proof}
  We want to solve $P(D)y = e^{rt}$. We know that
  \begin{equation*}
    P(D)e^{r_0t} = P(r_0)e^{r_0t},
  \end{equation*}
  for all $r$. However, since $P(r_0)$ is zero, we cannot divide by it.
  Instead, let us look at what happens near this point $r_0$ and differentiate with
  respect $r$.
  \begin{eqnarray*}
    \displaystyle  \displaystyle P(D)e^{rt} \qquad
    \displaystyle &=&
                      \qquad \displaystyle  P(r)e^{rt} \\
    \displaystyle \frac{\partial }{\partial r}\left(P(D)e^{rt}\right) \qquad
    \displaystyle &=&
                      \qquad \displaystyle \frac{\partial }{\partial r}\left( P(r)e^{rt}\right) \\
    \displaystyle P(D)\left(\frac{\partial }{\partial r}e^{rt}\right) \qquad
    \displaystyle &=&
                      \qquad \displaystyle  P'(r)\  e^{rt} + P(r)\  t\  e^{rt}
  \end{eqnarray*}
  In the case that $r_0$ is a repeated root with multiplicity $m$, then $P(r) = Q(r)(r-r_0)^{m}$,
  and
  \begin{equation*}
    \displaystyle  \displaystyle \frac{d^{m}}{dr^ m}P(r_0) \displaystyle  \neq \quad 0,
  \end{equation*}
  however, all lower derivatives are zero at $r$
  \begin{align*}
    \displaystyle  \displaystyle \frac{d^{m-1}}{dr^{m-1}}P(r_0)
    \displaystyle  &=& \displaystyle  0 \\
    \displaystyle \quad \vdots & & \displaystyle  \vdots \\
    \displaystyle P(r_0) \displaystyle  &=& \displaystyle  0.
  \end{align*}
  Differentiate both sides of the equation $m$ times with respect to $r$ to obtain a relationship:
  \begin{equation*}
    \displaystyle  \displaystyle P(D)\left(t^ m e^{rt}\right)
    \displaystyle  =
    \displaystyle  \left(P^{(m)}(r) + m\  t\  P^{(m-1)}(r)
      + \frac{m(m-1)}2 t^2P^{(m-2)}(r) + \dotsb + t^ mP(r)\right)e^{rt}
  \end{equation*}
  Evaluating at $r_0$, only the $m$th derivative term survives
  \begin{equation*}
    \displaystyle  \displaystyle P(D)\left(t^ m e^{r_0t}\right)
    \displaystyle  = \displaystyle  P^{(m)}(r_0)e^{r_0t},
  \end{equation*}
  which gives a particular solution to the differential equation
  $P(D)y = e^{r_0t}$ of the form
  $\displaystyle y_ p= \frac{t^ me^{r_0t}}{P^{(m)}(r_0)}$. 
\end{proof}
\clearpage
\subsubsection{Worked example}
\paragraph{Linear, constant coefficient, inhomogeneous ODEs}
We'll be solving linear ODEs with constant coefficients. \\
\begin{enumerate}
\item $\dot{x} + kx = 1$
\item $\dot{x} + kx = e^{-5t}$
\item $\dot{x} + kx = 4 + 7 e^{-5t}$
\end{enumerate}
The first step in solving these problems is finding the homogeneous solution.
We do this by setting the right hand side equal to 0.
Actually, note that all these three problems have the same exact left hand side.
So the homogeneous solution will be common to all of them.
The characteristic polynomial of $\dot{x} + kx$ is
\begin{equation*}
  P(s) = s + k 
\end{equation*}
We find the solution to the homogeneous problem by setting
\begin{equation*}
  P(s) = s + k = k 
\end{equation*}
That will tell us that $s = -k$.
Therefore, our homogeneous solution,
\begin{equation*}
  x_h = C e^{-kt}
\end{equation*}

For part 1, now we need to find a particular solution
that satisfies the differential equation $\dot{x} + kx = 1$.  
Now, this is an equation that we can actually solve by inspection.
If we assume that $x$ is a constant, then $\dot{x} = 0$.
\begin{align*}
  0 + kx &= 1 \quad \text{ if } x = \text{constant} \\
  x &= \frac{1}{k} 
\end{align*}
We'll denote this particular solution by the subscript $a$.
So $x_a$ is the particular solution to part 1.
Now, the general solution to pat 1 would be given by
\begin{equation*}
  x = x_a + x_h = \frac{1}{k} + C e^{-kt}.
\end{equation*}
We used \textbf{the method of inspection}, and that's not the most systematic way of doing it.
But for now, I just wanted to show you that there are ways to solve ODEs that are very simple just
by looking at them.\\

Now, for part 2 we're looking $\dot{x} + kx = e^{-5t}$.
And now we use the systematic method.
We're going to use the exponential response formula, or ERF.
We can only use the ERF because the right hand side or the forcing of this equation is exponential.
In order to calculate the the particular solution $x_b$,
We take the right hand side $e^{-5t}$ and divide by the characteristic polynomial $P$,
\begin{equation*}
  x_b = \frac{e^{-5t}}{P(-5)} = \frac{e^{-5t}}{-5 + k}  
\end{equation*}
We can write the general solution to part 2 by adding the particular solution
and the homogeneous solution, that is 
\begin{equation*}
  x = C e^{-kt} + \frac{e^{-5t}}{-5 + k}. 
\end{equation*}
Note an important thing here. What happens if $k = 5$?
Then this denominator goes to $0$, and this solution is undefined.
We'll need to look at another method to solve this.
But just one last thing that I want to point out is that the ERF could also have been used here. 
if we think of $1$ as $e^{0t}$.
That's true. That's an exponential.
And if we use the exponential response formula,
we would have gotten the same answer.\\

All right so we just found a solution for part 2.
But we notice that there is a problem when $k = 5$.
So this solution actually
\begin{equation*}
  x = C e^{-kt} + \frac{e^{-5t}}{k + 5} \quad \text{if } k \ne 5.   
\end{equation*}

If $k = 5$, we're actually solving the differential equation
\begin{equation*}
  \dot{x} + 5x = e^{-5t}
\end{equation*}
Now, since we saw that the exponential response formula as we know it didn't work,
we can use the method of variation of parameters.
So for variation of parameters we need a homogeneous solution $C e^{-5t}$.
But for the method of variation of parameters we only need one homogeneous solution.
So we can take $C$ to be $1$.
So now
\begin{equation*}
  x = u(t) e^{-5t}
\end{equation*}
We plug this into our ordinary differential equation, and we get 
\begin{equation*}
  \frac{d}{dt}(u e^{-5t}) + 5ue^{-5t} = e^{-5t}
\end{equation*}
Now, we use the product rule to simplify this term, which
\begin{align*}
  \frac{du}{dt} e^{-5t}n -5ue^{-5t} + 5u e^{-5t} &= e^{-5t} \\
  \frac{du}{dt} &= e^{5t} e^{-5t} \\
  \frac{du}{dt} &= 1 \\
  \int \frac{du}{dt} &= \int 1 \\
  u = t + c
\end{align*}
Now we plug that back into our expression for $x$.
\begin{equation*}
  x = (t+c)e^{-5t} = te^{-5t} + ce^{-5t} \quad \text{where } k = 5 
\end{equation*}
Note that contains a particular solution $te^{-5t}$, as well as the homogeneous solution
$ce^{-5t}$. 
So by using the method of variation of parameters, we got both solutions at the same time.
That's a nice feat of the method a variation of parameters. \\

Now, in part 3, we're asked to solve $\dot{x} + kx = 4 + 7 e^{-5t}$.
We need to note that the right hand side is a superposition of the problems that we solved.
\begin{equation*}
  \dot{x} + kx = 4\cdot (1) + 7 \cdot e^{-5t}.
\end{equation*}
And these were the right hand sides on parts 1 and 2.
So we're solving this problem.
Because this equation is linear, we can superimpose the solutions that we found in part 1 and 2
and get the particular solution for part 3.
So the particular solution for part 3 is recovered by
\begin{equation*}
  x_c = 4 x_a + 7 x_b  
\end{equation*}
Note that, once again, this is the particular solution.
If I want the full solution, I would get the general solution by adding the particular solution plus the homogeneous solution that we found before.
\begin{equation*}
  x = 4 x_a + 7 x_b + c e^{-kt}
\end{equation*}
And this is the most general solution
\clearpage

\subsubsection{Review: Basis of homogeneous solutions with linear operators}
Recall the method for finding a basis of solutions to a constant-coefficient homogeneous linear ODE, now written as $P(D)y=0$. Using operators, we can explain why it works.
\begin{example}
  Consider the ODE
  \begin{equation*}
    y^{\prime \prime \prime } - 10 y^{\prime \prime } + 31y'-30y = 0.
  \end{equation*}
\end{example}
Rewriting this using operator notation we have $P(D)y = 0$, where $P(r) = r^3-10r^2+31r-30$
is the characteristic polynomial of the ODE.
The trick now is to factor the operator, and proceed from there.
The characteristic polynomial factors as $P(r) = (r-2)(r-3)(r-5)$.
The order is $3$, so the dimension of the vector space of solutions is $3$.\\

Now
\begin{align*}
  e^{2t} &\text{  is a solution since } P(D) e^{2t} = p(2) e^{2t} = 0 e^{2t} = 0 \\
  e^{3t} &\text{  is a solution since } P(D) e^{2t} = p(2) e^{3t} = 0 e^{3t} = 0 , \text{ and}\\
  e^{5t} &\text{  is a solution since } P(D) e^{5t} = p(5) e^{5t} = 0 e^{5t} = 0 
\end{align*}

Just because we wrote down $3$ solutions does not mean that they form a basis:
If we had written down $e^{2t}\, , e^{3t}\, , 4e^{2t} + 6e^{3t}$, 
then they would \textbf{not} have been a basis, because they are linearly dependent
(and their span is only $2$-dimensional).\\

To know that $e^{2t}, \, e^{3t} , \, e^{5t}$ really form a basis,
we need to know that they are {\color{orange}linearly independent.}
Could it instead be that
\begin{equation*}
  e^{5t} = c_1 e^{2t}+c_2 e^{3t} \qquad \text{(as functions)}
\end{equation*}
for some numbers $C_1, \, c_2$? \\

One way to see that is no possible is to apply $(D-2)(D-3)$ to both side,
which would give
\begin{align*}
  \displaystyle  \displaystyle (D-2)(D-3)e^{5t}
  \displaystyle &= \displaystyle  (D-2)(D-3)\left( c_1 e^{2t} + c_2 e^{3t} \right) \\
  \displaystyle &= \displaystyle  c_1(D-2)(D-3)e^{2t} + c_2 (D-2)(D-3) e^{3t}
                  \qquad \text {(by linearity)} \\
  \displaystyle &= \displaystyle  c_1\cdot 0 + c_2 \cdot 0 = 0  
\end{align*}

The left hand side gives us
\begin{equation*}
  (D-2)(D-3)e^{5t} = (5-2)(5-3) e^{5t} \neq 0.
\end{equation*}
This contradiction implies that $e^{5t}$ is not a linear combination of $e^{2t}$ and $e^{3t}$.
The same argument shows that no one of $e^{2t}, \, e^{3t} , \, e^{5t}$ is a linear combination
of the other tow. Since $e^{2t}, \, e^{3t} , \, e^{5t}$ are linearly independent,
they form a basis of a $3$-dimensional space (which must be the space of all solutions,
since that too is $3$-dimensional). 
\clearpage

\subsubsection{Review: repeated roots with linear operators}

What about the case of repeated roots?\\

This case is less important than the others,
because if someone hands you a polynomial it's unlikely that two or more of its roots will coincide.
But it does happen, and it is interesting to think about what happens.\\

\begin{example}
  Find a basis of solutions to $D^3 y=0$. (
  The characteristic polynomial is $r^3$, whose roots with multiplicity are
  $0,\, 0,\, 0$.) 
\end{example}

\Solution Integrate three times:
\begin{align*}
  D^2 y &= c_1\\
  Dy &= c_1 t + c_2 \\
  y &= c_1 \frac{t^2}{2} + c_2 t + c_3 \\
  \displaystyle &= \underset {{\color{orange}{\textrm{general solution}}} }{C_1 t^2 + c_2 t + c_3}.          
\end{align*}
for some numbers $C_1=c_2 / 2, c_2,$ and $c_3$.
Since $t^2,\, t,\, 1$ are linearly independent, they form a basis for the space of solution.
\begin{example}
  Find a basis of solutions to $(D - 5)^3 y = 0$. 
\end{example}

\Solution \\
The characteristic polynomial is $(r-5)^3$, which a repeated root $5,\, 5,\, 5$,
so based on the previous example, we might hope that $e^{5t},\, te^{5t},\, t^2 e^{5t},\,$
are basis.
Let's now explain \textbf{why} these are solutions. \\
We know that $D - 5$ sends $e^{5t}$ to $0$.
What does $D - 5$ do to $ue^{5t}$, if $u$ is a function of $t$?
Using product rule:
\begin{align*}
  \displaystyle  (D-5) \,  u e^{5t}
  \displaystyle &= \left( \dot{u}\cdot e^{5t} + u \cdot 5 e^{5t} \right) - 5 u \cdot e^{5t} \\
  \displaystyle &= \dot{u} \cdot e^{5t}.
\end{align*}
Replacing $(D-5)$ by $(D-5)^2$ and $(D-5)^3$ on the left we get the following:
\begin{align*}
  \displaystyle  (D-5)^2 \,  u e^{5t}
  \displaystyle = \ddot{u} e^{5t}\\
  \displaystyle (D-5)^3 \,  u e^{5t}
  \displaystyle = u^{(3)} e^{5t}.
\end{align*}
So our guess was right! In order for $ue^{5t}$ to be a solution to
$(D-5)^3y = 0$ the function$u^{(3)}$ must be 0:i.e,
$u = a + bt + ct^2$ for some numbers $a,\, b,\, c,$ so the solutions are
\begin{equation*}
  \displaystyle u e^{5t} = a \,  e^{5t} + b \,  t e^{5t} + c \,  t^2 e^{5t},
\end{equation*}
are expected. \\

Since $1,\, t,\, t^2$ are linearly independent functions, so are $e^{5t},\, te^{5t},\, t^2 e^{5t}$
(any relation between the last there function could by divided by $e^{5t}$ to get a relation
between the first three). Thus $e^{5t},\, te^{5t},\, t^2 e^{5t}$ form a basis. \\

If a characteristic polynomial $P(r)$ has a root $r$ is repeated $k$ times, then
$e^{rt},\, te^{rt},\, t^2 e^{rt},\, \cdots ,\, t^{k-1} e^{rt}$ are independent solutions
to the differential equation $P(D)=0$. 
\clearpage

\subsubsection{Worked Examples}
\begin{example}
  Find the general solution to the differential equation
  \begin{equation*}
    2\ddot{x}+\dot{x}+x=1+2e^{t}.
  \end{equation*}
\end{example}

This is an inhomogeneous linear equation, so the general solution has the form
$x_p + x_h$, where $x_p$ is any particular solution and $x_h$ is the
general homogeneous solution.
The characteristic polynomial is $P(s) = 2s^2 + s + 1$, with roots$(-1 \pm \sqrt{7})/4$,
So and the general homogeneous solution is given by
\begin{align*}
  \displaystyle x_h(t)
  \displaystyle &=e^{-t/4}\left(a_1\cos \left( \frac{\sqrt {7} t}{4}\right)
                  +c_2\sin \left( \frac{\sqrt {7}t}{4}\right)\right) \\
  \displaystyle &=Ae^{-t/4}\cos \left(\frac{\sqrt {7}t}{4}-\phi \right)
                  \quad \text{ where } A = \sqrt{a_1^2 + c_2^2}
                  \quad, \phi = \arctan(c_2 / a_1)                    
\end{align*}
The inhomogeneous equation is $P(D)x = 1 + 2e^{t}$.
The input signal is a linear combination of $1$ and $e^t$,
so we can find particular solution to $P(D)x =1$ and $P(D)x = e^t$ separately,
then use superposition to construct a particular solution is $P(D) = 1 + 2e^t$.
if $x_1$ is a particular solution to $P(D)x = 1$, and $x_2$ is a particular solution
to $P(D)x = e^t$, then superposition says that a particular solution to
$P(D)x = 1 + 2e^t$ is given by
\begin{equation*}
  x_p = x_1 + 2x_2
\end{equation*}
The construct function $1$ is an exponential: $1=e^{0t}$. Thus $P(D)x = 1$ has a particular solution
\begin{equation*}
  x_1 = \frac{1}{P(0)} = 1
\end{equation*}
(More elementarily, we've learned to look for constant solutions when the right hand side is constant, and solving $P(D)c = 1$ gives $c = 1$.)\\
Similarly, the ERF tells us that
\begin{equation*}
  x_2 = \frac{1}{P(1)} e^t = \frac{1}{4} e^t  
\end{equation*}
is a particular solution to $P(D)x = e^t$. Thus
\begin{align*}
  x_p &= 1 + 2 \left( \frac{1}{4} e^t\right) \\
      &= 1 + \frac{1}{2} e^t
\end{align*}
is a particular solution to $P(D)x = 1 + 2e^t$. So the general solution
$2\ddot{x}+\dot{x}+x=1+2e^{t}$ is
\begin{equation*}
  \displaystyle  x\left(t\right)=
  1+\frac{1}{2}e^ t+Ae^{-t/4}\cos \left(\frac{t\sqrt {7}}{4}-\phi \right).
\end{equation*}

\begin{example}
  Find a particular solution to the equation
  \begin{equation*}
    \displaystyle  \ddot{x} + 8\dot{x} + 15 x = e^{-5t}
  \end{equation*}
\end{example}

The characteristic polynomial is $P(r) = r^2 + 8r + 15$. Since $P(-5) = 0$
we need to use the generalized ERF.\\

Computing we see that $P \prime (r) = 2r + 8$, and $P \prime (-5) = -2$.
Therefore the generalized ERF gives a particular solution of
\begin{equation*}
  x_p = \frac{te^{-5t}}{P \prime (-5)} = - \frac{te^{-5t}}{2}.
\end{equation*}

(Of course, there are other particular solution.)

\begin{exercise}
  ERF Concept Check
\end{exercise}
For which values $a$ does not the differential equation
\begin{equation*}
  \displaystyle  \frac{d^5 y}{dt^5} - y = e^{at}
\end{equation*}
\textbf{not} have a solution of $ce^{at}$ for some number $c$? 


The characteristic polynomial of the differential equation
\begin{equation*}
  \displaystyle  \frac{d^5 y}{dt^5} - y = e^{at}
\end{equation*}
is $r^5 -1$, which has roots are $1,\, e^{2 \pi i / 5},\, e^{4 \pi i / 5},\, , e^{(n-1) 2 \pi i / 5}$.
When $a$ is one of these values, substituting $y = ce^{at}$ into left side of the differential
equation gives $0$, not $e^{at}$.
Thus the differential equation does \textbf{not} have a solution of the form $ce^{at}$ when
$a=1$ or $a = e^{(n-1)2 \pi/5}$. 

\clearpage
\subsection{Recitation}

\subsubsection{Operator Notation}

\begin{problem}
  Operations on Operators
\end{problem}
Express $(D^3 -D)(x+y)$ as an operators acting on $x$ plus and operator action on y.
(if $(D^3 -D)(x+y) = Ax + By$, what do $A$ and $B$ equal in terms of $D$? )\\

By product rule ,
\begin{equation*}
  (D^3 -D)(x+y) = (D^3 -D)x + (D^3 -D)y  
\end{equation*}

\begin{problem}
  Superposition
\end{problem}

Let $x_1$ and $x_2$ be two solution to $(D^3 - D)x = 0$. Which of the following are also
solution to the same equation? Choose all that apply.
\begin{itemize}
\item $x_1 - x_2$
\item $x_1 x_2$
\item $ax_1$ for any constant $a$
\item $x_2 + 1$
\item $ax_1 + bx_2$ for any two constant $a$ and $b$.
\item $x_1 + x_2 + x_1 x_2$
\end{itemize}
By superposition, the solution is form of
\begin{equation*}
  c_1 x_1 + c_2 x_2 \qquad \text{ where } c_1,\, c_2 \text{ is any number.}, 
\end{equation*}
and the right side is equation is $0$, so both $x_1$ and $x_2$ can be constant function.\\

The answer is
\begin{align*}
  &x_1 - x_2\\
  &ax_1 \quad \text{ for any constant } a \\
  &x_2 + 1 \\
  &ax_1 + bx_2 \quad \text{for any two constant } a\, \text{and} \,b.
\end{align*}

\begin{problem}
  Homogeneous solutions
\end{problem}
Which of the following are solutions to the homogeneous equation
$(D^3 - D)x = 0$?\\

The characteristic polynomial is
\begin{equation*}
  r^3 - r = 0
\end{equation*}
The root of $r$ is $0,\, -1,\, 1$, so the homogeneous solutions for $(D^3 - D)x$ is
\begin{equation*}
  c_1 e^{0t},\, c_2e^{t},\, \text{ and } c_3 e^{-t}.   
\end{equation*}

\begin{problem}
  Particular solutions
\end{problem}

\begin{enumerate}
\item Use ERF (or generalized ERF) to find a particular solution to $(D^3 - D)x = e^{2t}$. \\
  The particular solution using ERF is
  \begin{equation*}
    x_p = \frac{e^{rt}}{P(r)} = \frac{e^{2t}}{2^3 - 2} = \frac{1}{6} e^{2t} 
  \end{equation*}
\item Use ERF (or generalized ERF) to find a particular solution to $(D^3 - D)x = e^{-t}$. \\
  The $P(r) = 0$, so suing generalized ERF is
  \begin{equation*}
    x_p = \frac{te^{rt}}{P^{\prime}(r)} = \frac{te^{-t}}{3 - 1} = \frac{1}{2} te^{-t}. 
  \end{equation*}
\item Use ERF (or generalized ERF) to find a particular solution to $(D^3 - D)x = 1$. \\
  The $(D^3 - D)x = 1 = e^{0t}$, so $r=0$.
  Using generalized ERF, $P^{ \prime} (r) = 3 r^2 - 1$. So
  The particular solution is
  \begin{equation*}
    x_p = \frac{te^{rt}}{P^{\prime} (r)} = \frac{te^{0t}}{0 - 1} = - t. 
  \end{equation*}
\end{enumerate}
\clearpage
\subsubsection{ERF}

Use ERF to find a particular solution of $\ddot{x} + 9x = e^{3t} + 9$.\\

Let particular solution of $\ddot{x} + 9x = e^{3t}$ as $x_a$ and
$\ddot{x} + 9x = 1$ as $x_b$. \\
By superposition,  the particular solution of  a particular solution of
$\ddot{x} + 9x = e^{3t} + 9$ is
\begin{equation*}
  x_p = x_a + 9 \cdot x_b
\end{equation*}
The characteristic polynomial is $r^2 + 9$, so the particular of
$x_a$ is
\begin{equation*}
  \frac{e^{rt}}{r^2 + 9} = \frac{e^{3t}}{3^2 + 9} = \frac{e^{3t}}{18}.  
\end{equation*}
The particular solution $x_b$ is
\begin{equation*}
  \frac{e^{rt}}{r^2 + 9} = \frac{e^{0t}}{0^2 + 9} = \frac{1}{9}. 
\end{equation*}
So,
\begin{equation*}
  x_p = x_a + 9 \cdot x_b = \frac{e^{3t}}{18} + 9 \cdot \frac{1}{9} =  1 + \frac{e^{3t}}{18}. 
\end{equation*}

\begin{problem}
  Higher order inhomogeneous
\end{problem}
Use ERF to find a particular solution of $\displaystyle {\frac{d^{4}x}{dt^{4}}-x=e^{-2t}}$. \\

The characteristic polynomial is $r^4 - 1$.
The particular solution using ERF is
\begin{equation*}
  \frac{e^{rt}}{P(r)} = \frac{e^{-2t}}{(-2)^4 -1} = \frac{e^{-2t}}{15}.  
\end{equation*}
\clearpage

\subsubsection{Using Operators, a Review}
\begin{problem}
  Review damped oscillators
\end{problem}
Consider the damped harmonic oscillator corresponding to the differential operator
$10D^2 + 2D + 5I$. \\
\begin{itemize}
\item If this were an undamped oscillator (damping term put to zero), find the natural angular frequency
  $\omega _n$\\
  
  The characteristic polynomial for undamped oscillator is $10r^2 + 5$.
  The roots of polynomial is $\pm i \frac{\sqrt{2}}{2}$.
  The homogeneous solution is
  \begin{equation*}
    e^{i \frac{\sqrt{2}}{2} t},\, e^{i \frac{\sqrt{2}}{2} t}
  \end{equation*}
  By Eular's Formular,
  \begin{equation*}
    e^{i \frac{\sqrt{2}}{2} t} = \cos(\frac{\sqrt{2}}{2} t) + i \sin (\frac{\sqrt{2}}{2} t). 
  \end{equation*}
  So the natural angular frequency $\omega _n $ is $\frac{\sqrt{2}}{2}$.

\item For the damped oscillator, what is the rate $a$ of exponential decay? \\
  
  The characteristic polynomial for undamped oscillator is $10r^2 + 2r + 5$.
  The roots of polynomial is $-\frac{1}{10} \pm i \frac{7}{10}$
  The homogeneous solution is
  \begin{equation*}
    \displaystyle e^{(-\frac{1}{10} + i \frac{7}{10})t},\, e^{(-\frac{1}{10} - i \frac{7}{10})t}
  \end{equation*}
  \begin{equation*}
    \displaystyle e^{(-\frac{1}{10} + i \frac{7}{10})t}
    \displaystyle = e^{(-\frac{1}{10})t} e^{(i \frac{7}{10})t}
  \end{equation*}
  So, the exponential decay $a$ is $-\frac{1}{10}$.

\item For the damped oscillator, find the angular frequency $\omega _d$?\\
  
  The angular frequency $\omega _2$ is $\frac{7}{10}$. 
\end{itemize}
\clearpage

\clearpage
\subsection{Complex Replacement, Gain and Phase Lag, Stability}

\subsubsection{Complex Replacement}
\textbf{\color{blue}Objectives}
\begin{itemize}
\item Use {\color{blue}complex replacement} to solve any inhomogeneous LTI
  system with {\color{blue} sinusoidal input}.
\item Find the {\color{blue}complex gain} of an LIT system in terms of
  the complex system response, and the complexified system input.
\item Describe the {\color{blue}phase shift} and {\color{blue} amplitude gain} of
  any LTI system with sinusoidal input signal in terms of the
  {\color{blue}complex gain}.
\item Describe {\color{blue}conditions for stability} in physical systems,
  and distinguish between {\color{blue}long term (steady state)} and
  {\color{blue}transient} behavior in a {\color{blue}stable} system. 
\end{itemize}
\clearpage
\subsubsection{Boston Harbor Example}

Suppose we are studying the tides in Boston Harbor.
Let $x$ the water level in Boston Harbor.
Let $y$ be the water level of the ocean.
Then the input is the ocean level $y$, which is responsible for the changing tides $x$ in Boston Harbor,
the system response.\\

\textbf{\color{blue} The Physics} \\

We assume that the ocean and the harbor are connected by a narrow channel
so that the flow is slow and not turbulent.
This allows us to assume that the flow rate is pressure driven, and is linearly proportional to the pressure difference.
Furthermore the pressure difference is linearly proportional to the difference in water level between the ocean and the harbor.

\begin{exercise}
  Modeling sinusoidal tides
\end{exercise}

Represent this system as ODEs.\\

The change in water level in the harbor is proportional to the difference in water level between the ocean
and the harbor, therefore
\begin{equation*}
  \dot{x} = k(y - x)
\end{equation*}

which is the same as
\begin{equation*}
  \dot{x} + kx = ky 
\end{equation*}

We wrote $k(y−x)$ not $k(x−y)$ because we make a habit of choosing positive parameters where possible.
We can see that $k$ must be positive because
if the water level in the ocean is higher than the water level in the harbor,
then the water level in the harbor will increase.
Similarly, if the water level in the ocean lower than the water level in the harbor,
the water level in the harbor will decrease.
Therefore the proportionality constant $k$ must be positive.
Notice that our equation is the same equation as Newton Cooling.
\clearpage
\subsubsection{Complex replacement method}

\paragraph{Introduction to complex replacement}
So I'm going to take the equation in the form
\begin{equation*}
  \dot{y} + ky = kq _e (t) \quad \text{ where} q _e(t) = \cos \omega t. 
\end{equation*}
And the input that I'm interested in is when this
is a simple one that you used on the visual that you did,
got two points worth of work for handing in today, $\cos \omega t$,
which is the physical input. \\

And $\omega$ is the angular frequency.
\begin{align*}
  \omega &= \quad \text{Angular Frequency} \\
         &= \quad \text{Number of Complete Oscillations in } 2 \pi
\end{align*}
In other words, it's the number of complete oscillations.
This $\cos \omega t$ is going up and down.
So a complete oscillation is it goes down and then returns to where it started.
So the number of complete oscillations in how much time, well, in the distance $2 \pi$
on the $t$-axis in the interval of length $2 \pi$.
For example, if $\omega = 1$, $\cos t$ takes $2 \pi$ to repeat itself.
If omega were 2, it would make two complete oscillations in the interval $2 \pi$.
So it's what happens in the interval $2 \pi$, not what happens in the time interval $1$ second,
which is the natural meaning of the word frequency.
There's always this factor of $2 \pi$ that floats around to make all your formulas
and solutions incorrect.\\

Now, what I'm out to do is, the problem is for the physical input $q_e =  \cos \omega t$,
find the response. In other words, solve the differential equation.
So we got to solve the differential equation using complex number. 
I'm going to \textbf{complexify}.
To use complex numbers, what you do is complexification of the problem.
So I'm going to complexify the problem, turn it into the domain of complex numbers.
So take the differential equation, turn it into a differential equation involving
complex numbers, solve that, and then go back to the real domain to get the answer.\\

In other words, I didn't give you the real answer.
The real answer, why one would do it, is because it's easier.
And what makes it easier is the fact that exponentials are very easy to integrate.
There's hardly anything easier to integrate than an exponential, well they're polynomials,
but unfortunately, polynomials occurred distressingly little in real life.
Since it's easier to integrate exponential,and therefore, try to change the trigonometric functions
into complex exponentials simply because the work will be easier to do.\\

So let's do it.
To change this differential equation $\dot{y} + ky = k \cos \omega t$, got $\cos \omega t$, 
I am  going to use the fact that $e^{i \omega}$, Euler's formula, that the real part of it
is $\cos \omega t$.
So I'm going to view this as the real part of this complex function, but I'll
throw in the imaginary part too since at one point we'll need it.\\

Now, what is the equation then it's going to turn into?
The complexified equation is going
\begin{equation*}
  \dot{y} + ky = k e^{iwt}
\end{equation*}
Now, I have a problem because $y$, in this equation, $y$ means the real function which solves that problem.
I, therefore, cannot continue to call this $y$ because I want $y$ to be a real function.
I have to change its name Since this is a complex function on the right side of the equation,
I'll have to expect a complex solution to the differential equation.
I'm going to call that complex solution $\tilde y$.
\begin{equation*}
  \tilde y ^{\prime} + k \tilde y = k e^{i \omega t}
\end{equation*}
Now, then that's what I would also use as the designation for the variable.
So $\tilde y$  is the complex solution, and it's going to have the form
\begin{equation*}
  \tilde y = y_1 + i y_2 \qquad \text{Complex Solution}
\end{equation*}

Find this complex solution, so the program is to find $\tilde y$.
That's the complex solution. And then I say all you have to do is take the real part of that, and that will
answer the original problem.
Then $y1$, will solve the original problem, the original real ODE.\\

\textbf{\color{blue}Complex replacement} is a method for finding \textbf{a particular solution} to
an inhomogeneous ODE
\begin{equation*}
  P(D) x = {\color{orange}{\cos \omega t}} ,
\end{equation*}
where $P$ is a real polynomial, and $\omega$ is real number.
\begin{enumerate}
\item Write the right hand side of the equation ${\color{orange}{\cos \omega t}}$
  as $\mathrm{Re\, }\left(e^{i\omega t} \right)$
  \begin{equation*}
    P(D)x = {\color{orange}{\mathrm{Re\, }\left( e^{i\omega t}\right)}} .
  \end{equation*}
\item Replace the right hand side of the differential equation with the complex exponential
  $e^{i \omega t}$.
  We need a new variable for the solution, which will be a complex function. Give the name
  $z$ for the unknown complex function. This \textbf{\color{blue} complexified}
  differential equation is this:
  \begin{equation*}
    P(D) {\color{blue}{z}}  =
    \underset {{\color{blue}{\text {complex replacement}}} }{{\color{blue}{e^{i\omega t}}} .}
  \end{equation*}
\item Use ERF(or generalized ERF if $P(i \omega) = 0$) to find a particular solution ${\color{blue}{z_ p}}$
  to the complexified ODE.
\item Computer $x_ p = \mathrm{Re\, }({\color{blue}{z_ p}} )$. Then $x _p$ is a particular solution
  to the \textbf{original} ODE. 
\end{enumerate}

\begin{exercise}
  Complexification concept check
\end{exercise}
The ocean tides are periodic with angular frequency $\omega$.
The input can be modeled as the sinusoidal function
$y = A \cos (\omega t)$.\\
What is the complexified ODE for the tide problem above?\\

Because $A \cos \omega t = \mathrm{Re\, }\left(Ae^{i\omega t}\right)$,
the complexified differential equation is
\begin{equation*}
  \dot z + kz = kAe^{i\omega t}.
\end{equation*}
\clearpage
\subsubsection{Why does complex replacement work?}

\begin{question}
  Why does the complex replacement method work?
\end{question}

If $z = x _1 + ix _2$ is solution to complex replacement ODE, i.e.,
\begin{eqnarray*}
  P(D)z &=& e^{i \omega t} \\
  P(D)(x _1 + i x _2) &=& \cos \omega t + i \sin \omega t  
\end{eqnarray*}
Since $P$ has real coefficients, taking the real parts of both side gives
\begin{equation*}
  P(D)x _1 = cos \omega t
\end{equation*}
which says that $x_ 1$ is a solution to the original ODE.
Note that for free we have actually solve another equation.
Taking the imaginary parts of both gives us
\begin{equation*}
  P(D)x _2 = \sin \omega t
\end{equation*}

Complex replacement is helpful also with other real input signals,
with any real-valued function that can be written
as the real part of a reasonably simple complex input signal.
Here are some simple examples that would be helpful to have memorized:
\begin{align*}
  &\text{\color{blue} Real input signal}  \qquad  &\text{\color{blue}Complex replacement} \\
  &\cos \omega t \qquad &e^{i \omega t} \\
  &A \cos(\omega t - \phi) \qquad &A e^{i(\omega t - \phi)} \\
  &e^{at} \cos \omega t \qquad &e^{(a + i \omega t)}
\end{align*}

Using complex arithmetic, there is a more complicated formula which can be derived as well 
\begin{align*}
  &\text{\color{blue} Real input signal}  \qquad  &\text{\color{blue}Complex replacement} \\
  &a \cos \omega t + b \sin \omega t \qquad &(a -bi)e^{i \omega t}
\end{align*}

Each function in the first column is the real part of the corresponding function in the second column. The nice thing about these examples is that the complex replacement is a constant times a complex exponential, so ERF (or generalized ERF) applies.
\clearpage
\subsubsection{Worked examples using complex replacement}

\begin{example}
  Find a solution to $\ddot{x} + 4x = \cos (2t)$
\end{example}
\Solution
\begin{enumerate}
\item Replace $cos (2t)$ by $\mathrm{Re\, }e^{2it}$, and complexify the ODE:
  \begin{equation*}
    \ddot{z} + 4z = e^{2it}. 
  \end{equation*}
\item Find the characteristic polynomial and apply ERF: $P(r) = r^4 +4$.
  We find that $P(2i) = 0$, so we must use the $ERF^{\prime}:\, P^{\prime} (r) = 2r$.
  The particular solution is
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{te^{2it}}{P^{\prime} (2i)} = \frac{te^{2it}}{4i}. 
  \end{equation*}
\item Take the real part to find the solution to the original equation
  \begin{equation*}
    \displaystyle x_ p \displaystyle = \mathrm{Re\, } (z_ p)
    \displaystyle = \frac{t\left( \cos (2t) + i \sin (2t)\right)}{4i}
    \displaystyle = \frac{t}{4} \sin (2t)
  \end{equation*}
\end{enumerate}

\begin{example}
  Find a particular solution $x_ p$ to 
\end{example}
\begin{equation*}
  \ddot{x} + \dot{x} + 2x = {\color{orange}{\cos (2t)}} .
\end{equation*}

\Solution
\begin{enumerate}
\item Since ${\color{orange}{\cos (2t)}}$ is the real part of ${\color{orange}{e^{2it}}}$, 
  replace ${\color{orange}{\cos (2t)}}$ by ${\color{orange}{e^{2it}}}$.
  \begin{equation*}
    {\color{blue}{\ddot{z}}}  + {\color{blue}{\dot{z}}}  + 2{\color{blue}{z}}
    = {\color{orange}{e^{2it}}} .
  \end{equation*}
\item Find the characteristic polynomial $P(r) = r^2 + r + 2$ and apply ERF,
  which says that one particular solution to this new ODE is
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{1}{P(2i)} e^{2it}
    \displaystyle = \frac{1}{-2 + 2i} e^{2it}. 
  \end{equation*}
\item A particular solution to the original ODE is
  \begin{equation*}
    {\color{orange}{x_ p = \mathrm{Re\, }(z_ p)
        = \mathrm{Re\, }\left( \frac{1}{-2+2i} e^{2it} \right).}}
  \end{equation*}
  This is a sinusoid expressed in complex form. \\
  It might be more useful to have answer in amplitude-phase form or
  as a linear combination of cosine and sine. \\

  \textbf{\color{blue} Converting to amplitude-phase form.} We have
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{1}{-2 + 2i} e^{2it}. 
  \end{equation*}
  To get the amplitude-phase form, we convert numerator and denominator to
  polar form so the division is easier. The denominator $-2 + 2i$ has absolute value
  $2 \sqrt{2}$ and angle $3 \pi / 4$, so in polar form
  \begin{equation*}
    \displaystyle -2 + 2i
    \displaystyle = 2 \sqrt{2} e^{i (3 \pi / 4)}. z_ p
    \displaystyle = \frac{e^{2it}}{2 \sqrt{2} e^{i (3 \pi / 4)}}
    \displaystyle = \frac{1}{2 \sqrt{2}} e^{i(2t - 3 \pi / 4)}
  \end{equation*}
\end{enumerate}
\Conclusion In amplitude-phase form
\begin{equation*}
  \boxed {x_ p = \frac{1}{2\sqrt {2}} \cos (2t - 3\pi /4). }
\end{equation*}

\textbf{\color{blue} Converting to a linear combination of $\cos$ and $\sin$:}
We have
\begin{equation*}
  \displaystyle z_ p
  \displaystyle = \frac{1}{-2 + 2i} e^{2it} 
\end{equation*}
To get the linear combination, we express numerator and denominator in rectangular form and then rationalize the denominator. We have

\begin{align*}
  \displaystyle e^{2it} \displaystyle &= \displaystyle  \cos 2t + i \sin 2t \\
  \displaystyle \frac{\cos 2t + i \sin 2t}{-2+2i}
  \displaystyle &= \displaystyle  \frac{\cos 2t + i \sin 2t}{-2+2i} \left(\frac{-2-2i}{-2-2i}\right) \\
  \displaystyle &= \displaystyle (\cos 2t + i \sin 2t) \frac{-2-2i}{8}
                  =(\cos 2t + i \sin 2t) \frac{-1-i}{4} \\
  \displaystyle &= \displaystyle  \frac{(-\cos 2t +\sin 2t) - i(\cos 2t +\sin 2t)}{4}.                  
\end{align*}

\Conclusion
\begin{equation*}
  \boxed {x_ p = -\frac{1}{4} \cos (2t) + \frac{1}{4} \sin (2t)}
\end{equation*}
\clearpage

\subsubsection{Damped sinusoidal inputs}
We can use \textbf{complex replacement} to solve any ODE of the form
\begin{equation*}
  P(D)x = e^{at}\cos (\omega t -\phi ).
\end{equation*}
Let us see how by working through an example.

\begin{example}
  Find a solution to $\ddot{x} + 2x = e^{-t} \cos (3t - \phi)$, where $\phi$ is a real number. 
\end{example}

\Solution
\begin{enumerate}
\item Replace the right hand side with a complex exponential:
  \begin{equation*}
    \displaystyle e^{-t}e^{i3t -i\phi}
    \displaystyle = e^{-i\phi}e^{(-1 + 3i)t}.
  \end{equation*}
  The complexified equation is
  \begin{equation*}
    \ddot{z} + 2z = e^{-i\phi}e^{(-1 + 3i)t}.
  \end{equation*}
\item Apply ERF. The characteristic polynomial is
  \begin{align*}
    P(r) &= r^2 + 2 \\
    P(-1 + 3i) &= (-1 + 3i)^2 + 2 = -6 -6i.     
  \end{align*}
  and complex solution is
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{e^{-i\phi}e^{(-1 + 3i)t}}{-6 -6i}, 
  \end{equation*}
  A solution to the original problem is then $X_ p = \mathrm{Re\, } (z_ p)$.
  The solution involves a sinusoid. Polar form is the most convenient for
  this problem, so we put the denominator in polar form:
  \begin{equation*}
    -6 -6i = 6 \sqrt{2} e^{-i 3 \pi / 4}. 
  \end{equation*}
  Then
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{e^{-i\phi}e^{(-1 + 3i)t}}{-6 -6i}
    \displaystyle = \frac{1}{6 \sqrt{2}} e^{-i\phi + i 3 \pi / 4}e^{(-1 + 3i)t} 
  \end{equation*}
  and
  \begin{equation*}
    \displaystyle x_ p
    \displaystyle = \mathrm{Re\, } (z_ p)
    \displaystyle = \frac{1}{6 \sqrt{2}} e^{-t} \cos (3t - \phi + 3 \pi / 4)
  \end{equation*}
\end{enumerate}

\paragraph{Complex replacement of sine}

\begin{equation*}
  y^{\prime \prime} - y^{\prime} + 2y = 10e^{-x} \sin x 
\end{equation*}

So the input of this function is $10e^{-x} \sin x $. 
It's a decaying oscillation.
A decaying exponential, and I want to find a particular solution.
Well, let's find a particular. \\

So we want a particular solution, and our equation is
\begin{equation*}
  (D^2 -D +2)y = 10e^{-x} \sin x
\end{equation*}
Now, let's complexify it to make this right side of
\begin{equation*}
  10e^{-x} \sin x = 10 e^{(-1 + i)x}
\end{equation*}
What is $e^{(-1 + i)x}$? This is the \textbf{imaginary part} of this complex exponential.
So this is imaginary part of $e^{-x} \sin x$. \\

Since this is a complex equation, I shouldn't call this $y$ anymore.
By my notation, I like to call it $\tilde y$.

\begin{equation*}
  (D^2 -D +2) \tilde y = 10 e^{(-1 + i)x}.
\end{equation*}

The $\tilde y$ to indicate that the solution we get to this is not going to be the solution to the original problem, but you'll have to take the imaginary part of it to get it.\\
So we're looking now for the complex solution to this complexified equation.
Well, the complex particular solution I can write down immediately.
\begin{align*}
  \displaystyle \tilde y_ p
  \displaystyle &= \frac{10 e^{(-1 + i)x}}{(-1 + i)^2 - (-1 + i) + 2} \\
  \displaystyle &= \frac{10 e^{(-1 + i)x}}{3 -3i} \\
  \displaystyle &= \frac{10}{3} \frac{(1 + i)}{(1 - i) \cdot (1 + i)} e^{(-1 + i)x} \\
  \displaystyle &= \frac{10}{3} \frac{(1 + i)}{2} e^{(-1 + i)x} \\
  \displaystyle &= \frac{10}{3} \frac{(1 + i)}{2} e^{-x} \left( \cos (x) + i \sin (x) \right) \\
  \displaystyle &= \frac{10}{3} \frac{(1 + i)}{2} e^{-x} \left( \cos (x) + i \sin (x) \right) \\
  \displaystyle &= \frac{5}{3}  e^{-x} (1 + i) \left( \cos (x) + i \sin (x) \right) 
\end{align*}

So we're practically at our solution.
The solution then finally is going to be $y_p $ is the imaginary part of $\tilde y_ p$, and what's that?
\begin{equation*}
  y_ p = \mathrm{Im\, } \left( \tilde y_ p \right)
  = \frac{5}{3}  e^{-x} \left(\cos (x) + \sin (x) \right)   
\end{equation*}
In amplitude-phase form
\begin{equation*}
  y_ p = \frac{5}{3} e^{-x} \sqrt{2} \cos (x - \pi / 4)
\end{equation*}

\clearpage

\subsubsection{Complex gain}

Our goal is to explain how the amplitude and phase lag depend on system parameters and the input frequency.
To do so, we will use our method of complex replacement and introduce the complex gain.\\

Let's state the general picture here for reference.
We have an LTI system modeled by the differential equation
\begin{equation*}
  P(D)x = Q(D)y 
\end{equation*}

with input signal $y$ and system response $x$.
The ERF together with complex replacement shows that if $y = \cos (\omega t)$,
then a particular solution is given by
\begin{equation*}
  x_ p  = \mathrm{Re\, } \left( G(\omega) e^{i \omega t}\right)
\end{equation*}
where
\begin{equation*}
  \displaystyle G(\omega)
  \displaystyle = \displaystyle \frac{Q(i \omega)}{P(i \omega)} \quad
  \text{if } P(i \omega) \neq 0. 
\end{equation*}

\paragraph{Complexification and ERF worked out}
The complexified equation is
\begin{equation*}
  P(D)z = Q(D) e^{i \omega t}. 
\end{equation*}

If $P(i \omega) \neq 0$, the ERF gives us a particular solution of the form
\begin{equation*}
  \displaystyle z_ p
  \displaystyle = \frac{Q(i \omega)}{P(i \omega)} e^{i \omega t}. 
\end{equation*}

We can express this as
\begin{equation*}
  \displaystyle z_ p = G(\omega) e^{i \omega t}.
\end{equation*}

Writing the complex gain in polar form, $G(\omega) = |G(\omega)| e^{-i \phi}$. we find
\begin{equation*}
  z_ p =\left|G(\omega )\right| e^{i(\omega t-\phi )}.
\end{equation*}
So the solution to the original OED is
\begin{equation*}
  x_ p =\left|G(\omega )\right| \cos {(\omega t-\phi )}.
\end{equation*}

This form leads directly to the polar form of the sinusoidal function $x_ p$.
Let's see how this works with the equation we used to model the tide in Boston Harbor
\begin{equation*}
  \dot x + kx = k\cos (\omega t).
\end{equation*}

Recall that we model the ocean tide by $\cos (\omega t)$, and this is regraded as the input signal.
The system response $x$ is the high of the water in harbor.\\

We use the method of complex replacement to solve the ODE for Boston harbor problem.

\begin{itemize}
\item The complex replacement ODE is
  \begin{equation*}
    \dot z + kz = k e^{i \omega t}
  \end{equation*}
  with input signal $e^{i \omega t}$.
\item One particular response determined by ERF is
  \begin{equation*}
    \displaystyle z_ p
    \displaystyle = \frac{Q(i \omega)}{P(i \omega)} e^{i \omega t}
    \displaystyle = \frac{k}{i \omega + k} e^{i \omega t}
  \end{equation*}
\item The ERF shows that the system response to a complex exponential input signal is a
  \textbf{constant multiple} of that input signal.
  That constant is the \textbf{\color{blue}complex gain}:
  \begin{equation*}
    \displaystyle  G(\omega ) \displaystyle  =
    \displaystyle
    \frac{\text {complexified system response}}{\text {complexified system input}}.
  \end{equation*}
  in the present case,
  \begin{equation*}
    G(\omega) = \frac{k}{i \omega + k}
  \end{equation*}
  and
  \begin{equation*}
    \displaystyle  z_ p =G(\omega )e^{i\omega t} =  \frac{k}{i\omega + k}e^{i\omega t}.
  \end{equation*}
  This complex number $G$, expressed as a ratio of two function of time is \textbf{constant}.
  It depends upon the system parameters, of course, but we regard them as fixed.
  We are interested in how it varies with the input angular frequency $\omega$, and
  write $G(\omega)$ to stress that functional dependence.
\item To get a particular solution to the original real ODE, take the real part of $z_ p$:
  \begin{equation*}
    x_ p = \mathrm{Re\, }\left( G(\omega ) e^{i\omega t}\right)
    = \mathrm{Re\, }\left( \frac{k}{i\omega + k}e^{i\omega t} \right)
  \end{equation*}
\item Now comes the best part of this method.
  Writing the particular solution in terms of $G$ leads directly to the polar form for $x_ p$.
  To find it, write out the polar expression for the complex number $G(\omega)$.
  \begin{equation*}
    G(\omega ) = \left| G(\omega ) \right|e^{-i\phi }.
  \end{equation*}
  In our case
  \begin{equation*}
    \left| G(\omega ) \right| = \frac{k}{\sqrt {\omega ^2+k^2}}
  \end{equation*}
  and so
  \begin{equation*}
    \displaystyle  z_ p \displaystyle =
    \displaystyle \frac{k}{\sqrt {\omega ^2+k^2}}e^{i(\omega t-\phi )}
    \qquad \text {and}
    \qquad x_ p \displaystyle  = \displaystyle \frac{k}{\sqrt {\omega ^2+k^2}}\cos (\omega t-\phi ).    
  \end{equation*}
  We have discovered that the gain is given by
  \begin{equation*}
    \text {gain} = g(\omega ) = \frac{k}{\sqrt {\omega ^2+k^2}}.
  \end{equation*}

  \textbf{\color{orange}General rule:}\\
  In general, the
  \begin{equation*}
    \text {gain} = g(\omega ) = \left|G(\omega ) \right|
  \end{equation*}
  and the
  \begin{equation*}
      \text {phase lag} = \phi = -\arg G(\omega ).
  \end{equation*}

\end{itemize}
Observe that the amplitude of the response is different than the amplitude of the input.
That difference in amplitude is the gain $g$. which is the magnitude of the complex gain
$g = |G|$.
The \textbf{\color{blue}phase lag} is $\phi = -\arg {G}$.

For the system,
\begin{equation*}
  \text {gain} = |G| = \frac{k}{\left| k+i\omega \right|} = \frac{k}{\sqrt {k^2 + \omega ^2}}
\end{equation*}
and
\begin{align*}
  \displaystyle  \displaystyle \text {phase lag} = -\arg G
  \displaystyle &= \displaystyle  -\left(\arg \frac{k}{k+i\omega }\right) \\
  \displaystyle &= \displaystyle  - \arg k + \arg (k+i\omega ) = \arg (k+i\omega ).  
\end{align*}

Note the last equality follows because $\arg k =0$
since $k$ is real and positive. Observe that in general, we have
\begin{align*}
  \displaystyle  \text {complex gain} = G
  \displaystyle &= \displaystyle  \frac{Q(i\omega )}{P(i\omega )}\\
  \displaystyle \text {phase lag} = -\arg G
  \displaystyle &= \displaystyle  \arg P(i\omega ) - \arg Q(i\omega ).
\end{align*}

\begin{exercise}
  Complex gain and LTI
\end{exercise}

Why is it enough to consider input signals of the type $\cos (\omega t)$?\\
What about an input signal of the type $A\cos (\omega t - \theta )$? \\
If you know that
\begin{equation*}
  x_ p = g\cos (\omega t - \phi )
\end{equation*}
is steady state response to
\begin{equation*}
  P(D) x = \cos (\omega t),
\end{equation*}
what is a steady state response to
\begin{equation*}
  P(D) x = A\cos (\omega t-\theta )?
\end{equation*}

This is the key idea behind LTI. A steady state response is given by
\begin{equation*}
  x_ p = g\cdot A \cos (\omega t - \theta - \phi ).
\end{equation*}

\clearpage
\subsubsection{Driving through the spring}

Now we will apply the method of complex gain to understand solutions to a more
complicated system — a mass-spring-dashpot system driven through the spring.
The general differential equation is
\begin{equation*}
  \ddot x + b\dot x + kx = ky
\end{equation*}

where $y$ is the input signal, namely the position of the far end of the spring,
and $x$ is the displacement of the mass.

\begin{exercise}
  Complex gain check
\end{exercise}

Find the complex gain for the system
\begin{equation*}
  \ddot x + b\dot x + 2x = 2\cos (t).
\end{equation*}

\begin{itemize}
\item The input is $\cos (t)$.
\item The complex replacement ODE is $\ddot z + b\dot z + 2z = 2e^{it}$.
\item Use ERF to find a particular solution
  \begin{equation*}
    z_ p=\frac{2 e^{it}}{i^2 + bi + 2} = \frac{2 e^{it}}{1+ bi}.
  \end{equation*}
\item The complex gain is
  \begin{equation*}
      \frac{z_ p}{e^{it}} = \frac{2}{1+bi}.
  \end{equation*}
\end{itemize}

\begin{exercise}
  Phase lag
\end{exercise}
Consider the equation
\begin{equation*}
  \ddot x + b\dot x + 2x = 2\cos (t).
\end{equation*}
If the damping constant $b$ starts at $1$ and is increased,
what happens to the \textbf{phase lag} ?\\

The phase lag increases—the phase lag is the argument of $\frac{2}{P(i)} = \frac{2}{1+bi}$.
As $b$ increases the argument increases.

\begin{exercise}
  Amplitude gain
\end{exercise}
Consider the equation
\begin{equation*}
  \ddot x + b\dot x + 2x = 2\cos (t).
\end{equation*}
If the damping constant $b$ starts at $1$ and is increased,
what happens to the \textbf{phase lag} ? \\

The amplitude decreases. The amplitude of the solution is the gain
$g=\frac{2}{|P(i)|}$.
As $b$ increases, the value of $|P(i)| = |1+bi|$ increases, so gain $g=\frac{2}{|P(i)|}$. 

\clearpage
\subsubsection{The meaning of LTI}
Here we explain why it is really enough to understand
the system response to the input signal $\cos (\omega t)$\\

We have been studying LTI, or Linear-invariant system.
``Time-invariant'' means that the system parameters are not changing,
or are change very slowly relative to the time scale we are interested in.
The implication of our input/output analysis is this:
If $x(t)$ is a system response to the input signal $f(t)$,
then if we delay the input signal by $t_0$ seconds, the output signal is the same
as before but delayed by $t_0$ seconds as well: $x(t - t_0)$ is system response
to the input $f(t - t_0)$. The system parameters are the coefficients
in differential equation; so ``time-invariant'' is the same as ``constant coefficients.''\\

Because our systems are also \textbf{linear}, if $x(t)$ is system response to $f(t)$,
then $Ax(t)$ is system response to $Af(t)$. Thus when studying a a linear time-invariant
system with sinusoidal input $A \cos (\omega - \phi)$, it is enough to consider
the input $\cos (\omega t)$ since linearity and time-invariance give the response
to all other sinusoidal inputs for free.

\begin{example}
  If
  \begin{equation*}
    P(D) x = \cos \omega t
  \end{equation*}
\end{example}
has $x_ p = A \cos (\omega t - \phi )$ as a particular solution, then shifting time by
$a = \alpha / \omega$ show that
\begin{equation*}
  P(D) x = \cos (\omega t - \alpha )
\end{equation*}
has $x_ p = A \cos (\omega t - \alpha - \phi )$ as a particular solution. \\

The gain and phase lag represent a relationship between the input and the output (both sinusoidal).
The gain is the ratio of the output amplitude to the input amplitude,
and the phase lag is the number of radians the output signal falls behind the input signal.
Because our system is time-invariant, those relationships between input and response are
\textbf{unchanged} by replacing the input signal $cos(\omega t)$ with $cos(\omega t - \alpha)$:
the gain is $A$ and the phase lag is $\phi$.\\

\begin{exercise}
  Time Invariance concept check
\end{exercise}

If $x_ p = A\cos (\omega t - \phi )$ is a particular solution to $P(D)x = \cos (\omega t)$, 
what is a solution to $P(D) x = \sin (\omega t)$?\\

Since $\sin (\omega t) = \cos (\omega t - \pi /2)$, the system response is
$A\cos (\omega t - \pi /2 - \phi ) = A\sin (\omega t - \phi )$,
as the gain and phase lag are unchanged.
\clearpage

\subsubsection{Worked example}
\paragraph{Review of complex replacement and time-invariance}
We'll review how to solve first order differential equations
with sinusoidal inputs using complex replacement and the exponential response formula.\\

\begin{enumerate}[label=\textbf{Part.\arabic*}]
\item \label{Part.1} Use complex techniques to solve
  \begin{equation*}
    \dot{x} + kx = \cos (\omega t) \qquad \text{ where } k,\, \omega \text{ is constant}. 
  \end{equation*}
  The general solution is
  \begin{equation*}
    x = x_ h + x_ p 
  \end{equation*}
  Set right side of equation to zero,
  \begin{equation*}
      \dot{x} + kx = 0
  \end{equation*}
  then solve it by separate variable,
  \begin{align*}
    \dot{x} + kx &= 0 \\
    \frac{1}{x} dx  &= -k dt \\
    \int \frac{1}{x} dx  &= \int -k dt \\
    \ln |x|  &= -kt + c_1 \\
    e^{\ln |x|}  &= e^{-kt + c_1} \\
    x  &= e^{c_ 1} e^{-kt}. 
  \end{align*}

  So, the homogeneous solution for $\dot{x} + kx$ is
  \begin{equation*}
    C_1 e^{-kt}. 
  \end{equation*}

  The particular solution of $\dot{x} + kx = \cos (\omega t)$. \\
  
  The complex replacement of $\cos (\omega t)$ is $\cos (\omega t) = \mathrm{Re\, }(e^{i \omega t})$. \\
  Complexified this ODE, 
  \begin{equation*}
    \dot{z} + kz = e^{i \omega t}. 
  \end{equation*}
  The characteristic polynomial is $P(D) = D + k$, Using ERF, 
  \begin{equation*}
    z_ p = \frac{1}{P(i \omega)} e^{i \omega t} = \frac{1}{i \omega  + k} e^{i \omega t}
    = \frac{k - i \omega}{k^2 + \omega ^2} e^{i \omega t}
    = \frac{k - i \omega}{k^2 + \omega ^2} \left( \cos (\omega t) + i \sin (\omega t) \right). 
  \end{equation*}
  Take real part of $z_ p$ is
  \begin{equation*}
    x_p = \mathrm{Re\, }(z_ p) 
    = \frac{1}{k^2 + \omega ^2} \left( k \cos (\omega t) + \omega \sin (\omega t) \right). 
  \end{equation*}
  So the general solution is
  \begin{equation*}
    x = C_1 e^{-kt} +
    \frac{1}{k^2 + \omega ^2} \left( k \cos (\omega t) + \omega \sin (\omega t) \right). 
  \end{equation*}
  
\item \label{Part.2}Use our work from \ref{Part.1} to solve
  \begin{equation*}
    \dot{x} + kx = F \sin (\omega t) \qquad \text{ where } F \text{ is constant}.
  \end{equation*}
  Complex replacement
  \begin{equation*}
    \sin (\omega t) = F \mathrm{Im\, }(e^{i \omega t}).
  \end{equation*}
  The complexified ODE
  \begin{equation*}
    \dot{z} + kz = Fe^{i \omega t}. 
  \end{equation*}
  Using linearity
  \begin{equation*}
    z_ p = \frac{F \left(k - i \omega \right)}{k^2 + \omega ^2}
    \left( \cos (\omega t) + i \sin (\omega t) \right). 
  \end{equation*}
  Take imaginary part of $z_ p$ is
  \begin{equation*}
    x_ p = \mathrm{Im\, } (z_ p)
    = \frac{F}{k^2 + \omega ^2} \left( - \omega \cos (\omega t) + k \sin (\omega t) \right). 
  \end{equation*}
  
\item Use the superposition principle to solve
  \begin{equation*}
    \dot{x} + kx =  \cos (\omega t) + 3 \sin (\omega t)
  \end{equation*}
  Let the solution of \ref{Part.1} as $x_a$ and \ref{Part.2} as $x_b$ then,
  \begin{align*}
    \dot{x}_ a + kx_ a &= \cos (\omega t) \\
    \dot{x}_ b + kx_ b &= F \sin (\omega t) = 3 \sin (\omega t), \text{ where } F = 3
  \end{align*}
  By linearity
  \begin{align*}
    \frac{d}{dt} (\underbrace{x_ a + x_ b}_{x}) +
    k(\underbrace{x_ a + x_ b}_{x}) =  \cos (\omega t) + 3 \sin (\omega t). 
  \end{align*}
  We can write down the solution to this equation by simply taking
  the sum of the solutions from \ref{Part.1} and \ref{Part.2}. \\
  So the particular solutions is
  \begin{align*}
    x_ p &= \frac{1}{k^2 + \omega ^2} \left( k \cos (\omega t) + \omega \sin (\omega t) \right)
    + \frac{3}{k^2 + \omega ^2} \left( - \omega \cos (\omega t) + k \sin (\omega t) \right) \\
         &= \frac{1}{k^2 + \omega ^2} \left( \left(k -3 \omega \right) \cos(\omega t) +
           \left( \omega + 3k \right) \sin (\omega t) \right)    
  \end{align*}  
  
\item use our work from \ref{Part.1} again, to solve
  \begin{equation*}
    \dot{x} + kx = \cos (\omega t - \phi) \qquad \text{ where } \phi \text{ is constant}.
  \end{equation*}
  Reform the equation
  \begin{equation*}
      \dot{x} + kx = \cos (\omega (t - \phi / \omega).   
  \end{equation*}
  This equation is same form of \ref{Part.1}. So using LTI
  \begin{align*}
    x_ p & = \frac{1}{k^2 + \omega ^2} \left( k \cos \left( \omega ( t - \phi / \omega) \right)
    + \omega \sin \left( \omega (t - \phi / \omega) \right) \right) \\
    &= \frac{1}{k^2 + \omega ^2} \left( k \cos (\omega t - \phi)  + \omega \sin (\omega t - \phi ) \right) \\
  \end{align*}
\end{enumerate}

\clearpage
\subsubsection{Stability} 
To do with the first order linear DE
\begin{equation*}
  \dot{y} + ky = q(t).
\end{equation*}

In this lecture, we've been discussing the case of exponential inputs
$q(t) = e^{(a + bi)t}$.
This is the case where complex numbers and ERF help.
But earlier in the class we used {\color{blue} variation of parameters} to find
a general integral solution for any input $q(t)$.\\
Considering the most general input $q(t)$.

\paragraph{Steady state and transients} \label{stablilty}

Let's look at the equation
\begin{equation*}
  q(t) = e^{(a + bi)t}.
\end{equation*}

When you solve it, let me remind you how the solutions look,
because that explains the terminology. \\
The solution looks like
--after you've done the integrating factor and multiplied through and integrated both sides--
in short, what you're supposed to do.
\begin{equation*}
  y = e^{{\color{orange}-k}t} \int q(t) e^{{\color{orange}k}t} dt + c e^{-k}
\end{equation*}
It will help you to remember the opposite signs.
If you think that when $q$ is a constant, $1$ for example,
you want these two $e^{-kt}$ and $e^{kt}$ to cancel out and produce a constant solution.
That's a good way to remember that the signs have to be opposite.
But I don't encourage you to remember the formula at all.
It's just a convenient thing for me to be able to use right now.
And then there's the other term which
comes by putting out the arbitrary constants explicitly, $c e^{-kt}$. 
So you could either write it this way, where this is somewhat vague, or you could
make it definite by putting $\int_0 ^t$ and change the dummy variable inside
according to the way the notes tell you to do it. \\

When you do this and if $k > 0$--
that's absolutely essential-- only when that is so, then this term, as I told you a week or so ago,
this $c e^{-k}$ goes to 0 because $k > 0$ as $t$ goes to infinity.
So this goes to 0 as t goes-- and it doesn't matter what $c$ is--as $t$ goes to infinity.
The terms, $e^{{\color{orange}-k}t} \int q(t) e^{{\color{orange}k}t} dt$, stays some sort of function.
And so this term is called the \textbf{\color{blue}steady state} or long term solution.\\

And this term $c e^{-kt}$ disappears, gets smaller and smaller as time goes on,
is therefore called the \textbf{transient} because it disappears as the time increases to infinity.
So $c e^{-kt}$ uses the initial value, let's call it $y(0)$, assuming that you started
the initial value when t was equal to $0$, which is a common thing to do, although of course
not necessary.
The starting value appears in this term. This one is just some function.\\
The general picture of the way that looks
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-steady_state}
  \caption{Image of steady state}
\end{figure}

Well, the steady state solution has this starting point.
Other solutions can have any of these other starting points.
So in the beginning, they won't look like the steady state solution.
But we know that as time goes on, they must approach it,
because $c e^{-kt}$ represents the difference between the solution and the steady state solution.
So this term is going to $0$, and therefore whatever these solutions of graph do to start out with,
after a while they must follow the steady state solution more and more closely.
They must, in short, be asymptotic to it.
So the solutions to any equation of that form will look like this.
Even if up here maybe it started at 127, that's OK.
After a while it's going to start approaching that green curve.\\

Of course, they won't cross each other.
But they are sort of like that's the rock star and these are the groupies trying to get close to it.
But something follows from that picture, which is the steady state solution?
What, in short, is so special about this green curve?
All these other white solution curves have the same property that all the other white curves
and the green curve, too, are trying to get close to them.
In other words, there is nothing special about the green curve.
It's just that they all want to get close to each other.
And therefore, though you can write a formula like this, there isn't one steady state solution.
There are many. Now, this produces vagueness.
So you talk about the steady state solution, which are you talking about?
I have no answer to that. The usual answer is whichever one looks simplest.
Normally the one that will look simplest is the one where $c$ is zero.
But if this is a peculiar function, it might be that for some other value of $c$,
you get an even simpler expression.\\

So the steady state solution, about the best I can say, either you integrate that, don't use an arbitrary constant and use what you get, or pick the simplest.
Pick the value of $c$ which gives you the simplest answer.
Pick the simplest function.
That's what's usually called the steady state solution.\\

\textbf{\color{orange} Remarks on \ref{stablilty}: }
For higher order systems, we haven't presented the general integral formula
for solving differential equations with arbitrary input.
So here we only discuss transients, steady state, and stability
in the case of complex exponential input for higher order systems.\\

A certain spring/mass/dashpot system is modeled by the LTI ODE
\begin{equation*}
  \ddot x + 7\dot x+12 x = 12f(t)
\end{equation*}
where $f(t)=\cos (2t)$ is the input signal.\\

\textbf{\color{blue}Question:} Suppose that the solution to this equation
with initial conditions $(x(0), \dot x(0)) = (2,3)$ is $x(t)$.
What can you say about the solution $y(t)$ to the same ODE with initial condition
$(y(0), \dot y(0)) = (3,-8)$?
\begin{itemize}
\item It isn't related to $x(t)$ in any way.
\item It oscillates.
\item ts graph becomes asymptotic to that of $x(t)$ as $t \to \infty$.
\item Its graph diverges from that of $x(t)$ as $t \to \infty$.
\end{itemize}

\Solution \\
The characteristic polynomial is $r^2 + 7r + 12$, and the roots are $-3$ and $-4$.
Thus the general homogeneous solution has form
\begin{equation*}
  x_ h = c_1 e^{-3t} + c_2 e^{-4t},
\end{equation*}

where $c_ 1$ and $c_ 2$ are constants determined by initial conditions.
All of these homogeneous solutions decay (rapidly!) to zero as $t$ grows to $\infty$.
So any solution with different initial conditions will become
asymptotic to that. Why is this?\\

The general solution to the original inhomogeneous ODE is

\begin{align*}
  \displaystyle  x \displaystyle &= x_ p + x_ h \\
  \displaystyle &=
                  \underbrace{\mathrm{Re\, }
                  \left( \frac{1}{8+14i} e^{2it} \right)}_{{\color{blue}{\text {steady state solution}}} }
                  + \underbrace{c_1 e^{-3t} + c_2 e^{-4t}}_{{\color{orange}{\text {transient}}} }.
\end{align*}
In general, for a damped oscillator forced with a sinusoidal input produces a sinusoidal output signal.
That output is a particular solution called a \textbf{\color{blue} steady-state solution},
because this is what the solution looks like as $t \to \infty$.
Every other solution is the steady-state solution plus a \textbf{\color{orange} transient},
where the transient is a function that decays to $0$ as $ t \to + \infty$. \\

Changing the initial conditions changes only the constants $c_ 1$ and $c_ 2$ in the homogeneous
solution above, so the steady-state solution is the same.
A system like this,in which changes in the initial conditions have vanishing effect on
the long-term behavior of the solution, is called $stable$. 
\clearpage
\subsubsection{Tests for stability in a second-order system}

\textbf{\color{blue}Stability} means that the long-term system behavior is independent of initial conditions.\\

\textbf{Stability test in terms of roots}.
A constant coefficient linear ODE of any order is stable if and only if every root of
the characteristic polynomial has negative real part.\\

We will explain this in the case of a second order system. For any second order system
\begin{equation*}
  m \ddot{x} + b \dot{x} + kx = 0
\end{equation*}
there are 3 cases for the roots of the characteristic polynomial.
\begin{enumerate}
\item The roots are complex conjugates: $a \pm bi$.
\item The roots are repeated and real: $s,\, s$.
\item The roots are distinct real number: $r_ 1 ,\, r_2$
\end{enumerate}

If the roots are complex conjugates, then the solution to the general solution to the homogeneous equation takes
the form $e^{at} \left(A \cos(bt - \phi) \right)$.
The homogeneous solution is transient only if the real part of the root is negative $(a<0)$.
If the real part is zero $a = 0$, the homogeneous solution oscillates forever
with constant amplitude;
if the real part is positive $(a>0)$, the homogeneous solution oscillates
and the amplitude grows exponentially as time goes on.\\

If the roots are real and repeated, then the homogeneous solution takes the form
$(A + Bt) e^{st}$, and these solution are transient only if $s < 0$.\\

If the roots are real and distinct, then the homogeneous solution takes the form
$c_ 1 e^{r_ 1 t} + c_ 2 e^{r_ 2 t}$ and these solutions are transient only if
$r_ 1 ,\, r_ 2 < 0$. \\

These conditions are collected in the table below.
All three cases are covered by the statement that the real part of the roots of
the characteristic polynomial must be negative.
\begin{align*}
  &\text{\textbf{\color{blue}Roots}}&
  &\text{\textbf{\color{blue}General solution}} x_ h &
  &\text{\textbf{\color{blue}Condition for stability}} \\
  &\text{complex } a \pm bi &
  &e^{at}\left(c_ 1 \cos (bt) \right)&
  & a < 0 \\
  &\text{repeated real} s,\, s &
  &e^{st} (c_ 1 + c_ 2 t)&
  &s < 0\\
  &\text{distinct real} r_ 1,\, r_ 2 & 
  & c_ 1 e^{r_ 1 t} + c_ 2 e^{r_ 2 t} &
  &r_ 1 , \, r_ 2 < 0 \\
\end{align*}

\paragraph{Conditions for stability}
This is our equation.

\begin{equation*}
  \ddot{y} + A \dot{y} + By =  f(t) \quad \text{ where } A, \, B \text{ are conditions. }
\end{equation*}

The question I'm asking is,
under what circumstances can I make that same type of analysis into steady state and transient?
Well, what does the solution look like?
The solution looks like
\begin{equation*}
  y = y_p + c_1 y_ 1 + c_ 2 y_ 2 
\end{equation*}
Therefore, to make $y = y_p + c_ 1 y_ 1 + c_ 2 y_ 2$ look like
this,$y = e^{-kt} \int q(t) e^{kt}dt + c e^{-kt}$,
the $c_ 1$ and $c_ 2$ contain the initial conditions.
This part $y_ p$ does not.\\
Therefore, if I want to say that the solutions look like a steady state solution
plus something which dies away, which becomes less and less important
as time goes on, what I'm really asking is, under what circumstances is this
$c_1 y_ 1 + c_ 2 y_ 2$ guaranteed to go to zero.?\\

So the question is, in other words, 
under what conditions on the equation constants $A$ and $B$ in effect
is what we're asking.\\
When does $c_ 1 y_ 1 + c_ 2 y_ 2$ go to $0$ as $t \to \infty$ regardless of what
$c_ 1$ and $c_ 2$ are, for all $c_ 1,\, c_22$?\\

Here
\begin{equation*}
  y = e^{-kt} \int q(t) e^{kt}dt + c e^{-kt}
\end{equation*}
there was no difficulty. We had the thing very explicitly,
and you could see it.
$k > 0$, $c e^{-kt}$ this goes to $0$.
And if $k < 0$, it doesn't go to zero. It goes to infinity. \\
Here
\begin{equation*}
  c_1 y_ 1 + c_ 2 y_ 2 
\end{equation*}
I want to make the same kind of analysis, except it's just going to be a little more trouble.
But the answer when it finally comes out is very beautiful.
So when are the $c_1 y_ 1 + c_ 2 y_ 2$ going to go to $0$?\\
First of all, you might as well have the definition.
All the good things that this is going to imply, if this is so--
in other words, \textbf{if they all go to 0,
everything in the complementary solution goes to 0}, then the ODE is called stable.
Some people call it asymptotically stable. I don't know what to call it.\\

I can make the analysis.
And then I use the identical terminology,
\begin{equation*}
  y = \underbrace{y_ p}_{\text{Steady State Solution }} +
  \underbrace{c_1 y_ 1 + c_ 2 y_ 2}_{\text{Transient}}
\end{equation*}
The transient because it goes to $0$.
This $y_ p$ is called the particular solution now that we labor so hard to get for
the next two weeks is the important part. It's the steady state part.
It's what lasts out to infinity after the other stuff has disappeared.
So this is the steady state solution.
And the differential equation is called stable. \\
It's of the highest interest to know when a linear differential
equation is stable in this sense, because you have a control.
You know what its solutions look like.
You have some feeling for how it's behaving in the long term.
If this is not so, each equation is a law unto itself, and you don't know. \\

So let's do the work.
For the rest of the period, what I'd like to do is to find out what the conditions are
which make this true.
Those are the equations which we'll have a right to call stable.
So when does this happen, and where is it going to happen?
I don't know. I guess here.\\


I think the first step is fairly easy, and it'll give you a good review of what
we've been doing up till now.
So I'm simply going to make a case by case analysis.
Don't worry, it won't take very long.
\begin{align*}
  &\text{\textbf{\color{blue}Characteristic Roots}}&
  &\text{\textbf{\color{blue} Homogeneous Solution}} &
  &\text{\textbf{\color{blue}Condition for stability}} \\
  & r_ 1 \neq r_ 2 &
  & C_ 1 e^{r_ 1 t}  + C_ 2 e^{r_ 2 t} &
  & r_ 1 < 0 , \, r_ 2 < 0\\
  & r_ 1 = r_ 2&
  & (C_ 1  + tC_ 2) e^{r_ 1 t}&
  & r_ 1 < 0  \\                 
  &r = a \pm bi & 
  &e^{at} \left(C_ 1 \cos bt  +  C_ 2 \sin bt \right) &
  & a < 0
\end{align*}

The ODE is stable-- so this is
\begin{equation*}
  \ddot{y} + A \dot{y} + By = f(t)
\end{equation*}
It doesn't matter. But psychologically you can put $0$ to the right side of equation.
It's stable if what?
But that's ugly. Make it beautiful.
The beautiful way of saying it is, \textbf{if all the characteristic roots have negative real part}.

If the characteristic roots, the $r$'s or the a plus or minus $bi$ have negative real part.
That's the form in which the electrical engineers will nod their head, tell you yeah, that's right.
The only case in which I really have to use real part is when I talk about the complex case,
because $a$ is just the real part of the complex number.\\

\begin{exercise}
  Stability concept check
\end{exercise}
Is the ODE
\begin{equation*}
  \displaystyle  x^{\left(3\right)}+\ddot{x}+\dot{x}-3x=\sin 7t
\end{equation*}
stable?\\
The characteristic polynomial is
\begin{equation*}
  \displaystyle  P\left(r\right)=r^3+r^2+r-3.
\end{equation*}
We see by inspection that $r = 1$ is a root of the characteristic polynomial.
Since this root is real and positive, the ODE is not stable (by the Stability test in terms of roots).

\clearpage

\subsubsection{Coefficients and tests for stability}

In the $2^{\text {nd}}$ order case, there is also simple test to check
for stability directly in terms of the coefficients:\\

\textbf{Stability test in terms of coefficients, $2^{\text {nd}}$ order case.}\\
Assume that $a_ 0,\, a_1,\, a_2$ are real numbers with $a_ 0 > 0$.
The ODE
\begin{equation*}
  (a_0 D^2 + a_1 D + a_2) x = F(t)
\end{equation*}
is stable if an only if $a_ 1 > 0$ and $a_2 > 0$. \\
\begin{proof}
  Recall the results for stability in terms of the roots of the characteristic polynomial.
  \begin{align*}
    &\text{\textbf{\color{blue}Roots}}&
    &\text{\textbf{\color{blue}General solution}} x_ h &
    &\text{\textbf{\color{blue}Condition for stability}} &
    &\text{\textbf{\color{blue} Characteristic polynomial}}\\
    &\text{complex } a \pm bi &
    &e^{at}\left(c_ 1 \cos (bt) \right)&
    & a < 0 &
    &r^2 - 2ar + (a^2 + b^2)\\
    &\text{repeated real} s,\, s &
    &e^{st} (c_ 1 + c_ 2 t)&
    &s < 0&
    &r^2 -2sr + s^2\\
    &\text{distinct real} r_ 1,\, r_ 2 & 
    & c_ 1 e^{r_ 1 t} + c_ 2 e^{r_ 2 t} &
    &r_ 1 , \, r_ 2 < 0&
    &r^2 -(r_1 + r_2)r + r_1 r_2\\
  \end{align*}
  By dividing by $a_0$, we can assume that $a_0 = 1$.
  Break into cases according to the table above.
  \begin{itemize}
  \item The radical is imaginary only if $a \pm bi$,
    we have $a < 0$ if and only if the the coefficients $-2a$
    and $a^2 + b^2$ are both positive.
  \item When the roots are $s,\, s$,
    we have $s < 0$ if and only if the coefficients $-2s$ and $s^2$
    are both positive.
  \item When the roots are distinct and real $r_1 \neq r_2$,
    both roots are less than zero if and only if the coefficients
    $-(r_1 + r_2)$ and $r_1 r_2$ are both positive.
    (Knowing that $-(r_1 + r_2)$ os positive means that at least
    one of $r_1,\, r_2$ is negative;
    if move over the product $r_1 r_2$ is positive,
    then the other root must be negative too.)     
  \end{itemize}
\end{proof}

\begin{remark}
  There is a generalization of the coefficient test to higher-order ODEs,
  called the \textbf{\color{blue}Routh–Hurwitz conditions} for stability ,
  but the conditions are much more complicated.
\end{remark}

\begin{exercise}
  Stability concept check
\end{exercise}
All spring/mass/dashpot systems,
\begin{equation*}
  m\ddot x + b\dot x + kx= F_{ext}, \qquad m, b, k > 0,
\end{equation*}
is stable?\\

All spring/mass dashpot systems are \textbf{stable}.
This is required by our physical model which came up with the equation
\begin{equation*}
  m\ddot x + b\dot x + kx= F_{ext},
\end{equation*}
and required the coefficients $m,\, b,$ and $k$  to be positive real numbers. \\
Physically this makes sense as well.
We know that there can be no such thing as a perpetual motion machine,
so in the absence of external forces,
we expect energy to dissipate in the form of friction or heat,
and thus our system will eventually be unmoving.
Any good differential equation model should also reflect this behavior.
\clearpage

\subsubsection{Upshot of stability}
Why are stable systems so great?
If we are interested in understand the long term behavior with respect to an exponential input,
it is enough to find one particular solution.
All other solutions will tend asymptotically to any particular solution.
And with ERF and its versions,
we have a simple way of determining one nice particular solution to any exponential input.\\

Keep in mind that while the long term behavior is enough to answer a question,
there are some situations where the initial conditions
and behavior as a system reaches steady state are important.
For instance as in the {\color{blue}example from Lecture 2}
about mixing saline and fresh water to create a salt water solution habitable for ocean fish.
\clearpage
\subsubsection{Worked Examples}
\paragraph{Damped sinusoidal signals}
Complex Replacement and Exponential Response Formula can be use to solve equation form
\begin{equation*}
  P\left(D\right)x=e^{at}\cos (\omega t-\phi )
\end{equation*}
where $P(D)$ is any LTI differential operator.

\begin{example}
  Solve
  \begin{equation*}
    2\ddot x+\dot x+x=e^{-t}\cos t.
  \end{equation*}
\end{example}

We found the general solution to the homogeneous version of the ODE in the example above.
To solve this ODE in general we just need to find a particular solution.
To do this, we complexify the ODE:
\begin{equation*}
  2\ddot{z}+\dot{z}+z=e^{(-1+i)t},
\end{equation*}
then apply the Exponential Response Formula:
\begin{equation*}
  z_ p=\frac{e^{(-1+i)t}}{P(-1+i)}.
\end{equation*}
To get $x_p$ we have to extract the real part of $zp$.
We have the choice to put $x_p$ in rectangular form or polar form.
To put $x_p$ in rectangular form, we expand
\begin{equation*}
  P(-1+i)=2(-1+i)^2+(-1+i)+1=-3i
\end{equation*}
so $z_p = i e^{(-1 + i)t}/3$, and the real part is
\begin{equation*}
  x_ p=-(1/3)e^{-t}\sin (t)\, .
\end{equation*}
To put $x_p$ in polar form, we write
\begin{equation*}
  \frac{1}{P(-1+i)}=ge^{-i\phi }
\end{equation*}
so that
\begin{equation*}
  z_ p=ge^{-i\phi }e^{(-1+i)t}=ge^{-t}e^{i(t-\phi )}
\end{equation*}
and real part is
\begin{equation*}
  x_ p=ge^{-t}\cos (t-\phi )
\end{equation*}
It's easy to check that you get the same answer!

\paragraph{Forced Oscillations Worked Example}
We'll consider ODEs that describe forced oscillations.
And in the solution process, we'll use complex replacement and the exponential response formula.
\begin{enumerate}[label=\textbf{Part.\arabic*}]
\item Find the general solution to
  \begin{equation*}
    \ddot{x} + 8x = \cos (\omega t). \quad {\color{blue} \omega ^2 \neq 8}
  \end{equation*}
  Why is this called undamped, forced?
  \begin{enumerate}[label=Step.\arabic*]
  \item To solve the associated homogeneous equation. \\
    Denote $x_h$ as homogeneous equation
    \begin{equation*}
      \ddot{x}_h + 8x_h = 0 
    \end{equation*}
    The characteristic polynomial is $P(s) = s^2 + 8$. 
    The roots of polynomial is $\pm \sqrt{8} i$.
    Because these roots are purely imaginary, we know that the solution will be a sinusoid.
    So, the homogeneous solution is
    \begin{equation*}
      x_ h= c_1 \cos (\sqrt{8}t) + c_2 \sin (\sqrt{8}t), 
    \end{equation*}
    where $c_1$ and $c_2$ are arbitrary constants.\\
    Now, note that I've written this in rectangular form.
    I could also write this in polar form,
    \begin{equation*}
      x_ h= A \cos (\sqrt{8}t - \phi). 
    \end{equation*}
    These are different representations for the same solution.
  \item Find a particular solution to the inhomogeneous equation.\\
    Using complex replacement, $\cos (\omega t) = \mathrm{Re\, }e^{i \omega t}$.
    Write down the complexified ODE, which would be
    \begin{equation*}
      \ddot{z} + 8 z = e^{i \omega t}. \\qquad x_ p = \mathrm{Re\, }(z_ p)
    \end{equation*}
    Apply Exponential Response Formula
    \begin{align*}
      z_ p &= \frac{1}{P(i \omega)} e^{i \omega t} \\
           &= \frac{1}{(i \omega)^2 + 8} e^{i \omega t} \\
           &= \frac{1}{8 - \omega ^2} e^{i \omega t} 
    \end{align*}
    Now, you might have noticed that the amplitude here depends on $\omega$.
    When $\omega ^2$ is near $8$, this amplitude is huge, because we're dividing by a very small number.
    If $\omega ^2 = 8$, then we're dividing by zero, and this just blows up.
    When that's the case, we're in a situation called \textbf{resonance},
    where the input frequency is the same as the natural frequency of the problem.
    So, just to be safe, we're going to solve this when $\omega ^2 \neq 8$.\\
    So now, since we're going to extract the real part of $z_p$
    \begin{align*}
      x_ p &= \mathrm{Re\, }\frac{1}{8 - \omega} e^{i \omega t} \\
           &= \frac{1}{8 - \omega ^2} \mathrm{Re\, }\left( \cos (\omega t) + i \sin (\omega t) \right) \\
           &= \frac{1}{8 - \omega ^2} \cos (\omega t)
    \end{align*}
    Now, we actually could have gotten this solution a lot faster, and maybe skipped a few steps,
    if we had noticed that we could have used the sinusoidal response formula,
    because \textbf{we have no damping} here.
    The sinusoidal response formula just says that the particular solution is
    equal to $\frac{1}{P(D)}$ at $i \omega$ times
    the right hand side of our original equation $\cos (\omega t)$.
    We can use that technique when \textbf{the ODE on the left hand side only has even derivatives},
    because then, our characteristic polynomial will only have even powers.
    And when you raise $i$ to an even power, you'll either get $1$ or $-1$.
    So, we'll have a real amplitude and then we can just multiply by the right hand side.
    So, if you notice that, it can make your computations more convenient.
    But if you're unsure, you can always go through this computation.
  \item So now we can actually write down the general solution,
    \begin{equation*}
      x = x_ h + x_ p = c_1 \cos (\sqrt{8}t) + c_2 \sin (\sqrt{8}t)
      + \frac{1}{8 - \omega ^2} \cos (\omega t)
    \end{equation*}
    And we actually could have answered this question,
    Why is this called undamped, forced?, right away. \\
    It's called undamped because we don't have a damping term.
    In other words, we don't have a term that's proportional to $\dot{x}$ in our ODE.
    And it's forced because we have this nonzero input on the right hand side.
  \end{enumerate}
  \item Find the general solution to
  \begin{equation*}
    \ddot{x} + 2 \dot{x} + 4x = \cos (3t). 
  \end{equation*}
  This is still a forced ODE, but now we have a damping term $2 \dot{x}$
  because we have a term that is proportional to $\dot{x}$.
  \begin{enumerate}[label=Step.\arabic*]
  \item Solve associated homogeneous solution, that's given by \\
    \begin{equation*}
      \ddot{x}_ h + 2 \dot{x}_ h + 4 x_ h = 0
    \end{equation*}
    The characteristic polynomial $P(s)$ is $s^2 + 2 s + 4$,
    and the roots are $-1 \pm \sqrt{3} i$. 
    Since the roots of the characteristic polynomial now have a real and an imaginary part,
    the solution to the homogeneous equation is written as follows.
    \begin{equation*}
      x_ h = e^{-t} \left( c_ 3 \cos (\sqrt{3} t ) +  c_ 4 \sin (\sqrt{3} t )\right), 
    \end{equation*}
    where $c_ 3$ and $c_ 4$ are arbitrary constants.
  \item Find a particular solution to the inhomogeneous equation. \\
    We're going to use complex replacement.
    And note that, our right hand side, $cos (3t)$ is a real part of
    $e^{i3t}$. \\
    So then the complexified ODE can be written as
    \begin{equation*}
      \ddot{z} + 2 \dot{z} + 4 = e^{i3t}
    \end{equation*}
    Now, we going to solve this equation and find particular solution for $z$. 
    Then, we'll take its real part, which will give us a particular solution for this equation.
    So, $x_ p$, or particular solution, is going to be equal to $\mathrm{Re\, }(z_ p)$.\\
    Use ERF,
    \begin{align*}
      z_ p  &= \frac{1}{P(3i)} e^{i3t} \\
            &= \frac{1}{(3i)^2 + 2*(3i) + 4} e^{i3t} \\
            &= \frac{1}{-9 + 6i + 4} e^{i3t}\\
            &= \frac{1}{-5 + 6i} e^{i3t}\\
    \end{align*}
    And we want to extract the real and imaginary parts from $z_ p$,
    so we're going to rationalize this complex fraction
    by multiplying by the complex conjugate of the denominator.
    \begin{equation*}
      z_ p = \frac{1}{-5 + 6i} e^{i3t} = \frac{-5 - 6i}{61} \left( \cos (3t) + i \sin(3t) \right)
    \end{equation*}
    Now, x sub p, our particular solution for this equation,
    is going to be the real part of this expression.
    \begin{align*}
            x_ p &= \mathrm{Re\, }(z_ p) \\
                 &= \mathrm{Re\, } \frac{1}{61} \left( -5 \cos (3t) + - 5 i \sin (3t)  -6i \cos (3t)
        + 6 \sin (3t) \right) \\
                 &= \frac{1}{61} \left( -5 \cos (3t) + 6 \sin (3t) \right) 
    \end{align*}
  \item The general solution is that
    \begin{equation*}
      x = x_ h + x_ p = e^{-t} \left( c_ 3 \cos (\sqrt{3} t ) +  c_ 4 \sin (\sqrt{3} t )\right)
      + \frac{1}{61} \left( -5 \cos (3t) + 6 \sin (3t) \right) 
    \end{equation*}
  \end{enumerate}
  And just want to point out a couple of things.
  This is a general solution
  \begin{equation*}
    c_1 \cos (\\sqrt{8}t) + c_2 \sin (\\sqrt{8}t) + \frac{1}{8 - \omega ^2} \cos (\omega t), 
  \end{equation*}
  for an undamped forced harmonic oscillator.
  And we can see that each of these terms is just a pure sinusoid,
  and their amplitudes do not decay over time.\\  
  However, in this case
  \begin{equation*}
    e^{-t} \left( c_ 3 \cos (\sqrt{3} t ) +  c_ 4 \sin (\sqrt{3} t )\right)
    + \frac{1}{61} \left( -5 \cos (3t) + 6 \sin (3t) \right), 
  \end{equation*}
  where we have a damping term, we note that our solution to the homogeneous equation
  actually decays to $0$ as $t \to \infty$. 
  So, we have a transient part of our equation,
  and this would be the steady state part of our solution.
  \begin{equation*}
    x = \underbrace{e^{-t} \left( c_ 3 \cos (\sqrt{3} t ) +  c_ 4 \sin (\sqrt{3} t )\right)}
    _{\text{Transient part}}
    + \underbrace{\frac{1}{61} \left( -5 \cos (3t) + 6 \sin (3t) \right) }
    _{\text{steady state part}}
  \end{equation*}
\end{enumerate}

\begin{example}
  Consider the harmonic oscillator with a sinusoidal forcing term:
  \begin{equation*}
    \ddot x+\omega _ n^2x=A\cos (\omega t).
  \end{equation*}
  Find a the complex gain, the gain, and the phase lag, and a particular solution.
  Food for thought: is this system stable?
\end{example}
This ODE has complex gain
\begin{equation*}
  G(\omega ) = \frac{1}{P(i\omega )}
\end{equation*}
where
\begin{equation*}
  \displaystyle  P(i\omega )=(i\omega )^2+\omega _ n^2=\omega _ n^2-\omega ^2.
\end{equation*}
Thus a particular solution is given by
\begin{equation*}
  x_ p=\mathrm{Re\, }\left(\frac{1}{\omega _ n^2-\omega ^2}Ae^{i\omega t}\right)
\end{equation*}
as long as the input frequency is different from the natural frequency of the harmonic oscillator.
Since the denominator is \textbf{real}, the real part is easy to find:
\begin{equation*}
  x_ p=A\frac{\cos (\omega t)}{\omega _ n^2-\omega ^2}\, .
\end{equation*}
Note that the gain is
\begin{equation*}
  g = G(\omega ) = \frac{1}{\omega _ n^2-\omega ^2}.
\end{equation*}
Since the complex gain is real, the phase lag is either
$0$ or $\pi$ depending on $\omega _ n > \omega$ or $\omega _ n < \omega$.
In particular, the same equation forced with a sine input curve
\begin{equation*}
  \ddot y+\omega _ n^2y=A\sin (\omega t)
\end{equation*}
has response
\begin{equation*}
  y_ p=A\frac{\sin (\omega t)}{\omega _ n^2-\omega ^2}\,
\end{equation*}
by time invariance.\\

This solution puts in precise form some of the things
we can check from experimentation with vibrating systems.
When the frequency of the signal is smaller than the natural frequency of the system,
$\omega < \omega _n$, the denominator is positive.
The effect is that the system response is a positive multiple of the signal:
the vibration of the mass is “in sync" with the impressed force.
As $\omega$ increases towards $\omega _n$ ,
the denominator of the particular solutions nears zero,
so the amplitude of the solution grows arbitrarily large.\\

When $\omega =\omega _ n$ the system is \textbf{in resonance} with the signal;
the Exponential Response Formula fails because the gain would be infinite there,
and there is \textbf{no} periodic (or even bounded) solution.
This phenomena is called resonance, and will be discussed in more detail
in the next section 11 Resonance, Frequency Response, and RLC circuits.\\

When $\omega > \omega _n$ the denominator is negative.
The system response is a negative multiple of the signal:
the vibration of the mass is perfectly ``out of sync'' with the impressed force.\\

Since the coefficients are constant here,
a time-shift of the signal results in the same time-shift of the solution:
\begin{equation*}
  \ddot x+\omega _ n^2x=A\cos (\omega t-\phi )
\end{equation*}
has the periodic solution
\begin{equation*}
  x_ p=A\frac{\cos (\omega t-\phi )}{\omega _ n^2-\omega ^2}.
\end{equation*}
The equations $\displaystyle x_ p=A\frac{\cos (\omega t)}{\omega _ n^2-\omega ^2}$
and $\displaystyle y_ p=A\frac{\sin (\omega t)}{\omega _ n^2-\omega ^2}$
will be very useful to us when we solve ODEs via Fourier series in
\textit{Fourier Series and Partial Differential Equations}. 
\clearpage
\subsection{Recitation}
\clearpage

\subsubsection{Sinusoidal input}
\textbf{ERF: } If $P(r) \neq 0$, then $\displaystyle x_ p = A\frac{e^{rt}}{P(r)}$
is a particular solution to $P(D)x = Ae^{rt}$.

\begin{problem}
  Particular solution
\end{problem}
Find a (particular) sinusoidal solution to the differential equation
\begin{equation*}
  \ddot x+2\dot x+2x=\cos (2t).
\end{equation*}

Complex replacement the right side of equation
\begin{equation*}
  \cos (2t) = \mathrm{Re\, }(e^{i2t}). 
\end{equation*}
Complexified the equation is
\begin{equation*}
  \ddot z+2\dot z+2z=e^{i2t}
\end{equation*}
The particular solution of inhomogeneous differential equation is
\begin{align*}
  z_ p &= \frac{1}{P(2i)} e^{i2t} \\
       &= \frac{1}{(2i)^2 + 2*(2i) + 2} e^{i2t}\\
       &= \frac{1}{-4 + 4i + 2} e^{i2t} \\
       &= \frac{1}{-2 + 4i} e^{i2t}
\end{align*}
To take real part of $z_ p$, multiple complex conjugate on the denominator
\begin{align*}
  \frac{-2 -4i}{(-2 + 4i)(-2 -4i)} e^{i2t}
  &= \frac{-2 -4i}{20} \left( \cos(2t) + i \sin(2t) \right) \\
  &= \frac{1}{20} \left(-2 \cos(2t) + -i2 \sin(2t)
    -4i \cos(2t) + 4 \sin(2t) \right)
\end{align*}
The real part is
\begin{equation*}
  \mathrm{Re\, } \left( \frac{1}{20} \left(-2 \cos(2t) + -2i \sin(2t)
      -4i \cos(i2t) + 4 \sin(i2t) \right) \right)
  = \frac{1}{20} \left(4 \sin(2t) - 2 \cos(2t) \right)
\end{equation*}
The particular sinusoidal solution is
\begin{align*}
  x_ p &= \frac{1}{20} \left(4 \sin(2t) - 2 \cos(2t) \right) \\
       &=  \frac{1}{20}  \sqrt{4^2 + 2^2} \cos (2t - \arctan (4 / -2)) 
\end{align*}


\begin{problem}
  IVP
\end{problem}
Find the solution to the differential equation
\begin{equation*}
  \ddot x+2\dot x+2x=\cos (2t).
\end{equation*}
that satisfies the initial value problem $x(0) = 0$ and $\dot{x} (0) = 0$.\\

To find associated homogeneous solution,
\begin{equation*}
  \ddot x+2\dot x+2x = 0. 
\end{equation*}
The characteristic polynomial is $s^2 + 2s + 2$ and the roots are
$-1 \pm i$.\\
The root of characteristic polynomial is complex number, So the
homogeneous solution of ODE is
\begin{equation*}
  x_ h =  e^{-t} \left( c_ 1 \cos(t) + c_ 2 \sin(t) \right)
\end{equation*}
The general solution is
\begin{equation*}
  x = x_ p + x_ h = \frac{1}{20} \left(4 \sin(2t) - 2 \cos(2t) \right)
  + e^{-t} \left( c_ 1 \cos(t) + c_ 2 \sin(t) \right).
\end{equation*}
Apply initial condition $x(0) = 0$ to general solution,
\begin{align*}
  x(0) = \frac{-2}{20} + c_1 &= 0 \\
  c_1 = 1/10. 
\end{align*}
The $\dot{x}$ is
\begin{equation*}
  \frac{1}{20}\left( 8 \cos(2t) + 4 \sin (2t) \right) +
  \frac{-1}{10} e^{-t} \cos (t) + \frac{-1}{10} e^{-t} \sin (t) 
  - c_ 2 e^{-t} \sin(t) + c_2 e^{t} \cos(t)
\end{equation*}

Apply another initial condition $\dot{x} (0) = 0$,
\begin{align*}
  \dot{x} _h (0) =  \frac{8}{20} + \frac{-1}{10} + c_2 &= 0 \\
  c_2 = -3 / 10 
\end{align*}

So, the solution for ODE is
\begin{equation*}
  x = \frac{1}{20} \left(4 \sin(2t) - 2 \cos(2t) \right)
  + e^{-t} \left( \frac{1}{10} \cos(t) - \frac{3}{10} \sin(t) \right)
\end{equation*}


\begin{problem}
  What does the solution look like?
\end{problem}
What is the steady state solution?\\

As $t \to \infty$, the terms of $\displaystyle
e^{-t} \left( \frac{1}{10} \cos(t) - \frac{3}{10} \sin(t) \right)$
goes to zero. So the steady state solution is
\begin{equation*}
  \frac{1}{20} \left(4 \sin(2t) - 2 \cos(2t) \right)
\end{equation*}

\begin{problem}
  Complex replacement
\end{problem}
Use complex replacement to find a particular solution to the differential equation
\begin{equation*}
  \ddot x+2\dot x+2x=e^{-t}\cos (2t).
\end{equation*}

Complex replacement of $e^{-t}\cos (2t).$ is $ e^{-t} e^{i2t} = e^{(-1 + 2i)t}$.\\
Complexified ODE is
\begin{equation*}
  \ddot z+2\dot z+2z = e^{(-1 + 2i)t}
\end{equation*}
Using ERF
\begin{align*}
  z_ p &= \frac{1}{P(-1 + 2i)} e^{(-1 + 2i)t} \\
  &= \frac{-1}{3} e^{(-1 + 2i)t} 
\end{align*}
Take real part of $z_ p$ is
\begin{align*}
  \mathrm{Re\, }(z_ p) &= \mathrm{Re\, } \left( \frac{-1}{3} e^{(-1 + 2i)t}\right) \\
                       &= \frac{-1}{3} e^{-t} \mathrm{Re\, } \left( \cos (2t) + i \sin (2t) \right) \\
                       &= \frac{-1}{3} e^{-t} \cos (2t)
\end{align*}
\clearpage

\subsubsection{An inhomogeneous second order ODE}
\textbf{ERF: } If $P(r) \neq 0$, then $\displaystyle x_ p = A\frac{e^{rt}}{P(r)}$
is a particular solution to $P(D)x = Ae^{rt}$.

\begin{problem}
  An inhomogeneous second order ODE
\end{problem}
Use ERF and the generalized ERF to find a particular solution to
\begin{equation*}
  \ddot x + 4x = 2\cos t + 3\cos (2t) + 4\sin (3t).
\end{equation*}
Let $x_1\, x_2$ and $x_3$ are the particular solutions of
$\cos t,\, \cos (2t)$ and $\sin (3t)$, then by superposition principle,
\begin{equation*}
  (c_1 x_1 + c_2 x_2 + c_3 x_3)^{\prime} + 4 (c_1 x_1 + c_2 x_2 + c_3 x_3) =
  2\cos t + 3\cos (2t) + 4\sin (3t).
\end{equation*}
Using complexified and ERF get the particular solutions
\begin{align*}
  &\text{Complexified }&
  &ERF&
  &Particular Solutions& \\
  &\ddot z + 4z = e^{it}&
  &\mathrm{Re\, }(\frac{1}{P(i)} e^{it}) = \mathrm{Re\, }(\frac{1}{3} e^{it}) &
  &x_1 = \frac{1}{3} \cos (t) \\                                                
  &\ddot z + 4z = e^{i2t}&
  &\mathrm{Re\, }(\frac{1}{P^{\prime}(2i)} te^{it}) = \mathrm{Re\, }(\frac{1}{4i} te^{i2t}) &
  &x_ 2 =\frac{t}{4} \sin (2t) \\
  &\ddot z + 4z = e^{i3t} &
  &\mathrm{Im\, }(\frac{1}{P(3i)} e^{i3t}) = \mathrm{Im\, }(\frac{-1}{5} e^{i3t}) &
  &x_ 3 = \frac{-1}{5} \sin (3t) 
\end{align*}
By linearity and superposition
\begin{equation*}
  x_ p = 2 x_1 + 3 x_2 + 4 x_3 = \frac{2}{3} \cos (t)
  + \frac{3t}{4} \sin (2t) + \frac{-4}{5} \sin (3t) 
\end{equation*}
\clearpage
\subsubsection{An inhomogeneous second order ODE with different inputs}
\textbf{ERF: } If $P(r) \neq 0$, then $\displaystyle x_ p = A\frac{e^{rt}}{P(r)}$
\begin{problem}
  When can a solution be of a particular form?
\end{problem}
Find $B$ so that $B \cos⁡ (\omega t)$ is a solution to the equation
\begin{equation*}
  \ddot x+\omega _ n^2x=A\cos (\omega t),
\end{equation*}
when this is possible.\\

Complex replacement of the  right side of equation is
\begin{equation*}
  A \cos (\omega t) = A e^{i \omega t}
\end{equation*}
Complexified the equation
\begin{equation*}
  \ddot z+\omega _ n^2z = A e^{i \omega t}. 
\end{equation*}
Using ERF
\begin{equation*}
  z_ p = \frac{A}{P(i \omega)} e^{i \omega t} = \frac{A}{\omega _ n^2 - \omega ^2} e^{i \omega t}.  
\end{equation*}
Take a real part of $z_ p$ is
\begin{equation*}
  \mathrm{Re\, }(z_p) = \mathrm{Re\, }(\frac{A}{\omega _ n^2 - \omega ^2} e^{i \omega t})
  = \mathrm{Re\, }
  \left( \frac{A}{\omega _ n^2 - \omega ^2} \left( \cos(\omega t) + i \sin (\omega t) \right) \right)
  = \frac{A}{\omega _ n^2 - \omega ^2} \cos (\omega t)
\end{equation*}
Therefore, the amplitude $B$ is $ \frac{A}{\omega _ n^2 - \omega ^2}$.

\begin{problem}
  What if we change the inputs?
\end{problem}
Does the same formula and value of $B$ work with cosine replaced
with sine in the ODE and in the solution? \\
The $B$ is gain of complex gain, so it is same formula.   
\clearpage
\subsubsection{Complex gain}
\begin{problem}
  Higher order system
\end{problem}
Find the complex gain of the following system given
that the input is $\cos ⁡t$ and the response is $x$.
\begin{equation*}
  (D^4+2D^2+5)x = (D^2+D)\cos (t)
\end{equation*}

The complex gain$G(\omega)$ of $P(D)x = Q(D)y$ is
\begin{equation*}
  G(\omega) = \frac{Q(i \omega)}{P(i \omega)} \quad \text{ if } P(i \omega) \neq 0
\end{equation*}
So complex replacement of $\cos t$ is $e^{it}$, the complex gain is
\begin{equation*}
  \frac{Q(i)}{P(i)} = \frac{i^2 + i}{i^4 + 2i^2 + 5} = \frac{-1 + i}{4}
\end{equation*}

\begin{problem}
  Variable complex gain
\end{problem}

Find the complex gain of the following system as a function of $a$ (where it is defined)
given that the input is $\cos⁡ at$ and the response is $x$.
\begin{equation*}
  (D^4+2D^2+5)x = (D^2+D)\cos (at)
\end{equation*}
The complex replacement of $\cos (at)$ is $e^{iat}$, so the complex gain $G(\omega)$ is
\begin{equation*}
  \frac{Q(i)}{P(i)} = \frac{(ai)^2 + ai}{(ai)^4 + 2(ai)^2 + 5} = 
\end{equation*}

\begin{problem}
  Vary the gain
\end{problem}
This problems is for the same the same differential equation
as in the problem above.
\begin{equation*}
  (D^4+2D^2+5)x = (D^2+D)\cos (at).
\end{equation*}

\begin{enumerate}
\item What is the magnitude of the complex gain when $a$ is close to $0$? \\
  The magnitude of gain $\left| G(\omega) \right|$ is
  \begin{equation*}
    \frac{\sqrt{a^4 + a^2}}{a^4 -2a^2 + 5}. 
  \end{equation*}
  As $a \to 0$, the numerator approach to zero, so the magnitude of gain goes to $0$.
\item What is the magnitude of the complex gain when $a$ is large?
  As $a \to + \infty$, the denominator grows much fast than numerator,
  so it goes to $0$.
\item Is this system stable?
  Solve the characteristic polynomial of $P(D)$,
  \begin{equation*}
    P(r) = r^4 + 2r^2 + 5 = (r^2 -1 + 2i)(r^2 + 1 + 2i). 
  \end{equation*}
  At least one of roost has positive, So this system \textbf{not} unstable. 
\end{enumerate}
\clearpage

\subsection{Resonance, Frequency Response, RLC circuits}
\subsubsection{Objective}

\textbf{Objectives}\\

\begin{itemize}
\item Understand that \textbf{\color{blue}resonance} occurs
  at the \textbf{\color{blue}input frequency} at
  which the amplitude of the system response is largest.
\item Find \textbf{\color{blue}purely resonant solutions}
  to differential equations from the generalized exponential response formula.
\item Express how the amplitude (gain) of the output signal changes
  as a function of the \textbf{\color{blue}angular frequency} of
  the input signal as a \textbf{\color{blue}Bode plot}.  
\end{itemize}
\clearpage
\subsubsection{Warm-up and review}

\paragraph{Harmonic oscillator with no input signal}
Suppose we model a swing on a playground
as a harmonic oscillator with the ODE
\begin{equation*}
  \ddot{x} + 9 x = 0.
\end{equation*}

In this model, $x$ is the angle of the swing away from vertical,
and this is a good model when $x$ is small. We can write this using operator notation as
\begin{equation*}
  P(D)x = 0, \qquad P(D) = D^2 + 9. 
\end{equation*}

\begin{align*}
  \text{Characteristic polynomial:} &\qquad P(r) = r^2 + 9. \\
  \text{Roots:} &\qquad \pm 3i.\\
  \text{Basis of complex solution:}  &\qquad e^{3it},\, e^{-3it}. \\
  \text{General real-valued solution:} &\qquad a \cos 3t + b sin 3t\, \text{ for real numbers } a,\, b.
\end{align*}

These are all the sinusoids with angular frequency $3$, the natural frequency.
\begin{equation*}
  A \cos (3t - \phi)
\end{equation*}
  
\begin{exercise}
  A particular solution
\end{exercise}
Now suppose that the swing is being pushed with a sinusoidal input signal, $cos \omega t$.
where $\omega \neq 3$. \\
Complexify and use the ERF to find a particular solution to the ODE
\begin{equation*}
  (D^2+9)x = \cos (\omega t).
\end{equation*}

The complex replacement of $\cos (\omega t)$ is $e^{i \omega t}$.
Complexify ODE is
\begin{equation*}
  (D^2+9)z = e^{i \omega t}. 
\end{equation*}
Find complex particular solution using ERF,
\begin{equation*}
  z_ p = \frac{1}{P(i \omega)} e^{i \omega t} = \frac{1}{(i \omega)^2 + 9} e^{i \omega t}
  = \frac{1}{9 - \omega ^2} e^{i \omega t}
\end{equation*}
Take a real part of $z_ p$
\begin{equation*}
  x_ p = \mathrm{Re\, }\left( \frac{1}{9 - \omega ^2} (\cos \omega t + i \sin \omega t) \right)
  = \frac{1}{9 - \omega ^2} \cos (\omega t)
\end{equation*}

\begin{exercise}
  The complex gain
\end{exercise}
Suppose that in the ODE
\begin{equation*}
  (D^2+9)x = \cos (\omega t)
\end{equation*}
the input signal is $\cos ⁡(\omega t)$, and the system response is $x$.
What is the complex gain $G(\omega)$?\\

Complexification and ERF worked out
\begin{equation*}
  P(D)z = Q(D) e^{i \omega t} 
\end{equation*}
The complex gain is
\begin{equation*}
  G(\omega) = \frac{Q(i \omega)}{P(i \omega)} = \frac{1}{9 - \omega ^2}.
\end{equation*}

\begin{exercise}
  Amplitude and the input frequency
\end{exercise}
What happens to the gain $g$,
which is the magnitude of the complex gain $G$ found above as $\omega$
approaches but is not equal to $3$?\\

When the $\omega \to \text{ near }3$ then
the denominator $9 - \omega ^2$ approaches to zero. So the magnitude of
complex gain is \textbf{increases}. 
\clearpage
\subsubsection{Near resonance}

\paragraph{Near resonance, an introduction}
what this has to do with the \textbf{phenomenon of resonance}.\\

Everybody knows at least one case of resonance, I hope.
A little kid is on a swing.
Back and forth.
Well, everybody knows that to make the swing go--
the swing has a certain natural frequency.
It swings back and forth like that.
It's a simple pendulum. It's actually damped.
But let's pretend that it isn't.
Everybody knows you want to push a little kid on a swing
so that they go high.
You have to push with essentially the same frequency
that the \textit{natural frequency} of the swing is.
Well, now, it's automatic, because when
you come back here, it gets to there,
and that's where you push.
So automatically, you time your pushes.
But if you want the kid to stop, you just do the opposite.
So that's resonance. \\

So my aim is, what is this physical phenomenon?
That to get a big amplitude, you should have them match the frequency.
What is that to do with a differential equation?
Well, the differential equation for that simple pendulum--
let's assume it's undamped--
\begin{equation*}
  y^{\prime \prime} + \underbrace{\omega _0 ^2}_{\text{Natural frequency}} = \cos \omega _1 t
\end{equation*}
-- I'm using $t$ now, since $t$ is time.
That will be our new independent variable.
$\omega _0 ^2$ is the natural frequency of the pendulum, or of the spring,
or whatever it is that's doing the vibrating.
What we're doing is driving that with the $\cos \omega _1 t$,
with something of a different frequency $\omega _1$ .
So this is the input, or the driving term,
as it's often called. Or sometimes it's called the forcing term.
And the point is, I'm going to assume that the frequency is
different.
The driving frequency is different from the natural frequency $\omega _0 ^2$.
So this is the input frequency.\\

Now, let's simply solve the equation and see what we get.
So if I write it using the operator.
\begin{equation*}
  (D^2 + \omega _0 ^2)y =  \cos (\omega _1 t)
\end{equation*}
It's a good idea to do this, because the formulas
are going to ask you to substitute into a polynomial.
So it's good to have the polynomial right
in front of you, to avoid the possibility of error.
Well, really what I want is the particular solution.
It's the particular solution that's
going to give me a pure oscillation.
And the thing to do is, of course, since this is $\cos$,
you want to make it complex.
So we're going to complexify the equation in order
to be able to solve it more easily.
And in order to be able to use those formulas.
So the complex equation is going to be
\begin{equation*}
  (D^2 + \omega _0 ^2) \tilde y =  e^{i \omega _1 t}
\end{equation*}
$\cos$ is the real part of $e^{i \omega _1 t}$.
So when we get our answer, we want
to be sure to take the real part of the answer.
I don't want the complex answer, I want its real part.

So now, without further ado, because of those beautiful--
the problem has been solved once and for all by using the substitution rule.
\begin{equation*}
  \tilde y_ p = \frac{1}{P(D)} e^{i \omega _1 t}
  = \frac{1}{\omega _0 ^2 - \omega _1 ^2} e^{i \omega _1 t}
\end{equation*}
But I want the real part of it, so there's one final last step.
The real part of that is what we call just
the real particular solution.
\begin{equation*}
  y_ p = \frac{1}{\omega _0 ^2 - \omega _1 ^2} \cos (\omega _1 t)
\end{equation*}
In other words, $\frac{1}{\omega _0 ^2 - \omega _1 ^2} \cos (\omega _1 t)$ is  the response.

This $\cos \omega _1 t$ is the input, and  that's what came out.
Well, in other words, what one sees
is that regardless of what natural frequency
the system wanted to use for itself, at least
for this solution, what it responds to is the driving,$\cos (\omega _1 t)$ frequency.
The only thing is, that the amplitude is changed.
And in a rather dramatic way.
If $\omega_ 1$-- depending on the relative sizes
of $\omega_ 0 ^2$ and $\omega_ 1$.\\

Now the interesting case is when $\omega_ 1 \approx \omega _0 ^2$.
When you push it,$\omega_ 1$ with approximately its natural frequency $\omega _0 ^2$,
then the solution is big amplitude. The amplitude is large.\\

Now, to all intents and purposes, that's resonance.
Pushing something with approximately the same frequency, something that wants to oscillate.
And you're pushing it with the same frequency-- approximately
the same frequency that it would like to oscillate by itself.
And what that does is it builds up the amplitude enormously.\\

\begin{example}
  We might try to model a swing on a playground as a simple harmonic oscillator.
  Recall that a harmonic oscillator has a natural frequency $\omega _n$.
  When you push your kid sister on a swing,
  the key is to get in sync with the natural frequency of the swing.
  You keep pushing on regular intervals with the same force, but your sister swings higher and higher.
\end{example}

Let's model the swing-and-sister setup by a sinusoidally driven harmonic oscillator
$\ddot{x}+\omega _ n^2x=A\cos (\omega t)$.\\
We find a periodic solution using the exponential response formula
\textit{provide that} $\omega \neq \omega _ n$:
\begin{equation*}
  \displaystyle x_p \quad
  \displaystyle = \quad
  \displaystyle A\frac{\cos (\omega t)}{\omega _ n^2-\omega ^2}.
\end{equation*}

Notice that as $\omega$ gets closer to $\omega_ n$,
the amplitude of this particular solution grows larger.\\

What happens when the two frequencies coincide,
that is $\omega = \omega _n$? This is the phenomenon known as pure resonance , which we explore next.
\clearpage

\subsubsection{Pure resonance}

\paragraph{Finding the resonant response}
If $\omega_ 1 = \omega_ 0$--
so now our equation looks like
\begin{equation*}
  (D^2 + \omega_ 0 ^2)y = \cos (\omega _0 t)
\end{equation*}
But this time the driving frequency--
the input frequency-- is $\omega_ 0$ itself.
Then the same analysis, a lot of it is exact--
well, I'd better be careful.
Let's go through the analysis again very rapidly.

What we want to do is first complexify it and then solve.
So the complexify equation will be
\begin{equation*}
  (D^2 + \omega_ 0 ^2) \tilde y = e^{i \omega _0 t}
\end{equation*}
But now $i \omega$ is a $0$ of this polynomial,$ (D^2 + \omega_ 0 ^2)$ .
That's why I picked it, right?
If I plug in $i \omega_ 0$.
I get $(i \omega_ 0)^2 -  \omega _ 0 ^2 = 0$. 
So I'm in the second case, because $i \omega _0$ is a simple root, simple zero, of
$D^2 + \omega _0 ^2$. 
Therefore, the complex particular solution is now
\begin{equation*}
  \tilde y _p = \frac{1}{P^{\prime}(D)}{te^{i \omega _0 t}}
  = \frac{1}{2\omega _0 i}{te^{i \omega _0 t}}  
\end{equation*}
And now I want the real part of that, which is what?
\begin{equation*}
  z_ p = \mathrm{Re\, }\left(\frac{t}{2\omega _0 i} \left( \cos (\omega _0) + i \sin (\omega _0) \right) \right)
  = \frac{t}{2\omega _0}  \sin (\omega _0 t)
\end{equation*}
So that's our particular solution now. \\


Well, it looks different from that guy,
doesn't look like that anymore.
What does it look like?
Well it shows the way to plot such things is basically as an oscillation of frequency $\omega _0$,
but it's amplitude is changing.
So the way to do it is, as always, if you have a basic oscillation, which is neither too fast nor too slow,
think of that as the thing and the other stuff multiplying it, think of as changing the amplitude
of that oscillation with time.
So the amplitude is that function-- $\frac{t}{2 \omega _0}$
So just as we did when we talked about damping, you plot that
and it's negative on the picture.
So this is the curve--the function whose graph is $\frac{t}{2 \omega _0}$,
that's the changing amplitude-- as it were--
and then the function itself does what oscillation it can
but it has to stay within those lines.
So the thing that's oscillating is $\sin (omega _0 t)$,
which would like to be a pure oscillation
but can't because its amplitude is being changed by that thing,
so it's doing this and now the rest I have
to leave to your imagination.\\


In other words, what happens when $omega _0$ equal--
when the driving frequency is actually equal to $omega _0$,
mathematically this turns into a different-looking solution, one
with steadily increasing amplitude.
The amplitude increases linearly, like the function $\frac{t}{2 \omega _0}$. \\

The case in which we drive a harmonic oscillator by the natural frequency
$\omega _n$ is known as \textbf{\color{blue} pure resonance}.
\begin{equation*}
  (D^2 + \omega _ n^2)x = \cos (\omega _ n t).
\end{equation*}

To find a particular solution, we find a particular solution instead to the complexified equation
\begin{equation*}
  (D^2 + \omega _ n^2)z = e^{i \omega _ n t}.
\end{equation*}

Note that $i \omega _n$ is a root of the characteristic polynomial
$P(r) = r^2 + \omega _ n^2$. But $P'(r) = 2r$, so
$P'(i\omega _ n) = 2i \omega _ n \neq 0$ and we use $\text{ERF}^{\prime}$
to find a complex particular solution
\begin{equation*}
  z_ p = \frac{te^{i\omega _ n t}}{P'(i \omega _ n)}
  = \frac{te^{i\omega _ n t}}{2 i \omega _ n}
  = \frac{t(\cos \omega _ n t + i\sin \omega _ n t)}{2 i \omega _ n}).
\end{equation*}
The real part of $z_ p$ is a real-valued particular solution
\begin{equation*}
  \mathrm{Re\, }(z_ p)=x_ p = \frac{t\sin (\omega _ n t)}{2\omega _ n}.
\end{equation*}

Even though our input signal is sinusoidal, the response is not a sinusoid.
The response is an oscillating function whose oscillations grow linearly
without bound as time increases.\\

\textbf{\color{blue}Pure resonance} is a phenomenon that occurs
when a harmonic oscillator is driven
with an input sinusoid whose frequency is at the natural frequency:

\begin{itemize}
\item the gain becomes larger and larger as
  the input frequency approaches the natural frequency, and
\item when the input frequency \textit{equals} the natural frequency,
  any particular solution is unbounded.
\end{itemize}

\begin{exercise}
  Example of Pure Resonance
\end{exercise}

Find a particular solution to the ODE
$\,  \ddot x + 4 x = 2 \cos 2 t \,$ using complex replacement and
$\text{ERF}^{\prime}$.\\

The complex replacement of $2 \cos 2 t$ is $2 e^{i2t}$.
Complexified is
\begin{equation*}
  z_ p = \frac{1}{P(D)} 2 e^{i2t}. 
\end{equation*}
The $P(i2) = 0$, so we use $\text{ERF}^{\prime}$
\begin{equation*}
  z_ p = \frac{1}{P^{\prime} (2i)} 2t e^{i2t}
  = \frac{2t}{4i}  e^{i2t} 
\end{equation*}
The real part of $z _p$ is
\begin{equation*}
  \mathrm{Re\, } (z _p) = x _p 
  = \mathrm{Re\, } \left(\frac{2t}{4i} \left( \cos (2t) + i \sin (2t)\right) \right)
  = \frac{t}{2} \sin (2t)
\end{equation*}
\clearpage

\subsubsection{Resonance with damping}
In a realistic physical situation, there is at least a tiny amount of damping,
and this prevents the runaway growth of the amplitude of the system response
that we saw in the previous section.\\

\begin{question}
  What happens if $\omega = 3$ exactly, but there is a tiny amount of damping, so that the ODE is
  \begin{equation*}
    \ddot{x} + \underset {{\color{blue}{\text {damping term}}} }{b \dot{x}} + 9 x
    = \underset {{\color{orange}{\text {input signal}}} }{\cos \omega t}
  \end{equation*}
  for some small positive constant $b$?
\end{question}


The new characteristic polynomial is $P(r)=r^2+br+9$.
Since $3i$ is no longer a root, the ERF applies.
The complex gain is $\displaystyle G= \frac{1}{P(3i)} = \frac{1}{3bi},\,$
and the gain is $\displaystyle |G| = \frac{1}{3b}$.
This is large, but the oscillations are bounded; there is a steady-state solution.

\begin{exercise}
  Preparation and review
\end{exercise}
Rewrite the equation
\begin{equation*}
  m\ddot x + b\dot x + kx = 0
\end{equation*}
for the homogeneous spring-mass-dashpot system by dividing through by $m$ as
\begin{equation*}
  \ddot x + 2p\dot x + \omega _ n^2 = 0.
\end{equation*}
When this system is underdamped, we write $\omega d$ for the angular frequency
of the oscillations of the solution to this homogeneous equation. \\

Find $\omega _ d^2$ in terms of $\omega _ n$ and $p$\\

The roots of characteristic polynomial for the underdamped system are the complex number.
Therefore, the discriminate $(2p)^2 - 4 \omega _ n^2 < 0$. \\
So, the damping frequency is 
\begin{equation*}
  \displaystyle \omega _ d \displaystyle= \frac{\sqrt{4 \omega _ n^2 - 4p^2}}{2}
  \displaystyle= \sqrt{ \omega _ n^2 - p^2}. 
\end{equation*}
So $\omega _ d^2$ is $\omega _ n^2 - p^2$.\\
\clearpage
\textbf{Remark:} The only case where the damped frequency exists when
$\sqrt {p^2-\omega _ n^2}$ is imaginary. In this case,
$\omega _ n^2 > p^2,\,$ and the damped frequency $\omega _d$ satisfies
the pythagorean relationship
\begin{equation*}
  \omega _ n^2 - p^2 = \omega _ d^2.
\end{equation*}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-damped_frequency_pythagorean}
  \caption{ $\omega _d$ satisfies the pythagorean relationship.}
\end{figure}

\textbf{\color{orange} Note for paragraph Damped resonance:} \\

We need to prepare you for below paragraph because we are entering in the middle.
In the paragraph below, $\omega _0$ is used instead of $\omega _n$
for the natural angular frequency of the spring-mass-dashpot;
$\omega _1$ is used instead of $\omega _d$ for the natural damped frequency,
or damped pseudofrequency. \\

We use the notation
\begin{equation*}
  m\ddot x + b\dot x + kx = f_1(t)
\end{equation*}
or the spring-mass-dashpot system driven through the mass. We rewrite this as
\begin{equation*}
  \ddot x + 2p \dot x + \omega _ n^2 x = f_2(t)
\end{equation*}

by dividing through by $m$:

\begin{align*}
  2p \qquad &= \qquad \frac{b}{m} \, \\
  \omega _n^2 \qquad &= \qquad \frac{k}{m} .
\end{align*}

\paragraph{Damped resonance}
The spring mass, damping
\begin{equation}
  \label{eq:3}
  m\ddot x + b\dot x + kx = f_1(t) 
\end{equation}
divide by mass $m$
\begin{equation*}
  \ddot x + 2p \dot x + \omega _ n^2 x = f_2(t)  
\end{equation*}

And it's only after you've divided up by the $k$--
by the $m$ that you're allowed to call this
the square of the natural frequency.
So $\omega _0$ is the natural, undamped frequency.
If this term, $2p \dot x$, were not there that $\omega _0$
would give the frequency with which the little spring would
like to vibrate by itself.\\

Now, further complication is that the visual
uses neither of these.
\begin{equation}
  \label{eq:5}
  \ddot x + b \dot x + k = f_3 (t)
\end{equation}
I think we'll have to fix this in the future.
So in other words, the problem is
that $b$ is OK, can't be confused with $c$.
On the other hand, the $k$ on the equation~\ref{eq:3} $k$ is
not the same $k$ on the equation~\ref{eq:5} as that,
because on the equation~\ref{eq:3}  $k$, to be converted into--
either you have to assume the mass is
$1$ or you have to divide through by it, in which case--
So, what I'm trying to say is don't automatically
go to a formula one place and assume
it's the same formula in another place.
You have to use these equivalences.
You have to look and see how the basic equation was written
and then figure out what the constant should be.\\


Now, there was something called--
when we analyzed this before, and this has happened
in recitation-- there was the natural $\omega _1$--
the damped frequency, then I'll call it
the natural damped frequency.
The book calls it the pseudo frequency.
because the function if you have $0$ on the right-hand side
but have damping, the function isn't periodic, it decays,
does this.
Nonetheless, it still crosses the t-axis at regular
intervals, and therefore almost everybody just
casually refers to it as the frequency
and understands it's the natural damped frequency.\\

Now, the relation between them is
given by the little picture,
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-damped_frequency_pythagorean}
  \caption{ $\omega _d$ satisfies the pythagorean relationship.}
\end{figure}

but I didn't emphasize it enough.
Here is omega 0.
Here is a right angle.
This side is omega 1 and $p$ is the damping.
So in other words, $\omega _0$ is fixed because it's
fixed by the spring, that's the natural frequency
of the spring by itself.

If you have damping, if you're damping the motion,
then the more you damp it, the bigger this side gets
and therefore the smaller $\omega _1$ is.
The bigger the damping then the smaller
the frequency with which the damped thing vibrates.
That's sort of intuitive.
And vice versa-- if you decrease the damping to almost $0$,
well then you'll make $\omega _1$ almost the same size as $omega _0$--
this must be a right angle--
and therefore if there's very little damping,
this natural damped frequency will
be almost the same as the original frequency.
So the relation between them
\begin{equation*}
  \omega _1^2 = \omega _0^2 - p^2
\end{equation*}
and this comes from the characteristic roots
of the damped equation.
Now, the third frequency which now enters, 
if you've got a damped spring, what
happens when you impose a motion on it
with yet a third frequency?
So in other words, drive the damped spring.
\begin{equation*}
  \ddot x + 2p \dot x + \omega _0^2 y = \cos \omega t
\end{equation*}
I'm going to drive that with an undetermined frequency,
$\cos \omega t$.
And my question now is--
see, it's not going to be able to resonate in the correct--
you really only get true resonance
when you don't have damping, that's
the only time where the amplitude can build up
indefinitely.
But nonetheless, for all practical--
and you never have--
there's always some damping, unless you
are a perfect vacuum or something,
there's always some damping.
So $p$ isn't 0, can't be exactly 0.
So the problem is which $\omega$ gives --
which frequency in the input--
which input frequency gives the maximal
amplitude for the response?\\

We solved that problem when it was undamped
and the answer was easy--
$\omega$ should equal $\omega _0$.
But when it's damped, the answer is different.
And I'm not asking you to do it in general,
I'm giving you some numbers.
But nonetheless, it still must be the case you--
so I'm giving you a specific values of $p$ and $omega_ 0$.
That's on the problem set, of course one of them
is tied to your recitation.
But the answer is--
I'm going to give you the answer, the general formula
for the answer to make sure that you don't get widely astray--
let's call that $\omega _r$, the resonant omega.
This isn't true resonance, your book
calls it practical resonance, again, most people just
call it resonance, so you know what I mean now, type of thing.
The answer is very curious and I would
love to have someone explain it to me.
Of course, I can derive it mathematically
but that's not entirely satisfying.
It is $omega _r$ is very much like that,
maybe we should have written this one down in the same form.
What would you expect?
Well, what I would expect is that $\omega _r$ should be $\omega _1$.
The damped system has a natural frequency, $omega _1$.
The resonant frequency should be the same
as that natural frequency with which the damped system wants
to do it's thing.
And the answer is that's not right, it's a little lower.
\begin{equation*}
  \omega _r = \sqrt{\omega _0^2 + 2p^2}
\end{equation*}

\paragraph{Resonant frequency recap}
There are three frequencies that come into play when we drive a spring-mass-dashpot system with a sinusoidal input.
\begin{align*}
  &\omega _n \qquad \qquad \text{the natural (undamped) frequency,} \\
  &\omega _d \qquad \qquad \text{the natural damped (pseudo) frequency,} \\
  &\omega _r \qquad \qquad \text{the {\color{blue}resonant frequency} .} 
\end{align*}
\clearpage

\subsubsection{Frequency response and amplitude response}
Given any ODE
\begin{equation*}
  P(D)x = Q(D)\cos (\omega t)
\end{equation*}
the complex gain is a complex function given by
\begin{equation*}
  G(\omega ) = \frac{Q(i \omega )}{P(i \omega )} = ge^{-i\phi } \quad \text {(in polar form)}.
\end{equation*}

The gain of the response $x$ is $g= |G(\omega )|$,
which can also be thought of as a function of the input sinusoidal frequency $\omega$.
The phase lag of the response $-\phi =\arg (G(\omega ))$
can similarly be thought of as a function of $\omega$. \\

In engineering, the graph of gain as a function of $\omega$ is called
\textbf{\color{blue} Bode plot}(Bode is pronounced Boh-dee), and is usually on a log-log scale.
Alternatively, a \textbf{\color{blue} Nyquist plot}
hows the trajectory of the complex gain $G$ as $\omega$ varies.
The Bode plots contain, at a glance, all of the information about the resonant response $\omega _r$.
By looking at the Bode plot of the amplitude as a function of frequency,
we can observe any vertical asymptotes (pure resonant values) or local maxima (resonant values).
Sometimes the gain is monotonically decreasing, this is the case of no resonance.\\

\textbf{\color{orange} Note on below paragraph: }
In the paragraph that follows, the input is the entire right hand side
$F_0 \cos (\omega t)$.
The response is $x$.
The \textit{gain} is called the \textit{amplitude response}. \\

\paragraph{Amplitude response worked example}
So today I'd like to talk about resonant frequency response.
And specifically, we're going to take
a look at a couple of different differential equations.
And we're asked to graph the amplitude response.
\begin{enumerate}[label=\textbf{Part.\arabic*}]
\item $\ddot x + 4x = F_0 cos (\omega t)$\\
  The particular solution for the equation is
  \begin{equation*}
    x_ p = \mathrm{Re\, }(\frac{F_ 0}{P(D)} e^{it}) = \frac{F_ 0}{4 - \omega ^2 } \cos (t) 
  \end{equation*}
  \clearpage
  
  Now the amplitude response is defined as a ratio of
  the output amplitude of a differential equation to the input amplitude
  of a differential equation.\\
  So I'm going to draw the amplitude response now.
  \begin{equation*}
    \displaystyle \frac{\frac{F_ 0}{4 - \omega ^2}}{F_0}
    \displaystyle= \frac{1}{4 - \omega ^2}
  \end{equation*}
  So we have $\omega$ on x-axis and we see that, when $\omega = 2$,
  there's an asymptote. When $\omega = 0$, we have $1/4$.

  \begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{image-graph_amplitude_partA}
    \caption{Graph amplitude response of Part 1}
  \end{figure}
  
  So notice how when we drive the system with frequency $2$,
  the amplitude response goes to infinity.
  As a result, we call this frequency the resonant frequency.
  
\item $\ddot x + \dot x + 4x = F_0 cos (\omega t)$ \\
  The particular solution for the equation is
  \begin{equation*}
    x_ p = \mathrm{Re\, }(\frac{F_ 0}{P(D)} e^{it})
    = \frac{F_ 0}{\sqrt{(4 - \omega ^2)^2 - \omega^2  }} \cos (t - \phi) 
  \end{equation*}
  The amplitude of output is $\displaystyle \frac{F_0}{|P(i\omega)|} $ and
  The input amplitude is $F_0$, so amplitude response is
  \begin{equation*}
    \frac{1}{|P(i\omega)|} = \frac{1}{\sqrt{(4 - \omega ^2)^2 - \omega^2  }}
  \end{equation*}
  \clearpage
  
  Now there's the question of how to graph this.
  And we see that--
  well, first off, the square root's an increasing function.
  And we see that we're one over an increasing function.
  So there's a trick, which is to just  look first at sketching this piece which
  is under the radical sign.
  And if you look at maximizing-- trying to maximize this
  function, so finding the critical points--
  we see that in this case, we have one minimum to $(4 - \omega ^2)^2 + \omega ^2$.
  And this is when $\omega = \sqrt{\frac{7}{2}}$.
  OK, so when I go to sketch this now, we have omega.
  We have the amplitude response.
  \begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{image-graph_amplitude_partB}
    \caption{Graph of Amplitude response Part 2}
  \end{figure}

  So we end up with a maximum at $\sqrt{7/2}$ and then decay to infinity.
  And again, y intercept is going to be $1/4$.
  So when $\omega$ is $\sqrt{7/2}$, the graph is the peak amplitude response.
  So note that in this case by adding damping, what we've done
  is we no longer have an asymptote at $\omega = 2$.
  But we now have a finite amplitude,  which occurs at $\omega$ equals $\sqrt{7/2}$.
  
\item $\ddot x + \dot x + 4x = F_0 cos (\omega t)$ \\
  The amplitude gain is
  \begin{equation*}
     \frac{1}{\sqrt{(4 - \omega ^2)^2 + 36 \omega ^2}}
  \end{equation*}
  So now if we'd like to plot this function,
  we can still do the same trick and try to maximize or find
  the critical points in the denominator under the radical.
  \begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{image-graph_amplitude_partC}
    \caption{Graph of Amplitude response Part 3}
  \end{figure}

  And if we did this, in this case we would find that the only critical point
  is when $\omega = 0$. Secondly, if we look at $\omega \to \infty$,
  we see that the denominator goes to infinity.
  So this whole quantity must go to $0$.
  when $\omega = 0$, it's going to start off at $1/4$.

  I've just argued that it goes to 0 as omega goes to infinity.
  And since there are no critical points,
  we must smoothly paste the function between the two.
  And in fact, it's always decreasing.
  So the amplitude response in this case
  is just a decreasing function.

\item Discuss resonance for each system. \\
  So in Part 1, we had no damping.
  And we saw that there was a resonance at $\omega =  2$.
  And the resonance manifested itself in the amplitude response graph with a pole
  or a divergent asymptote at $\omega = 2$.
  So as you drive the system close to $\omega = 2$,
  the amplitude of the system starts to diverge.
  In Part 2, we introduce damping into the system.
  So we still have a very large amplitude response at $ \omega = \sqrt{7/2}$
  However, it's no longer infinite.
  And then lastly, when we increased damping even further,
  so we had the $6 \dot x$ terms, the presence of a peak disappeared.
  And in fact, the amplitude response  just monotonically decayed from one fourth to zero.
  So it just constantly decreased to zero.
\end{enumerate}

\begin{exercise}
  Mathlet activity 1
\end{exercise}

The mathlet below shows the steady state response of a spring-mass-dashpot system in series being driven sinusoidally through a piston at the bottom.
The mass in this system is $1kg$. The equation modeling this system is
\begin{equation*}
  \ddot x + b\dot x + k x = b\dot y, \qquad y = \cos (\omega t).
\end{equation*}

\href{http://mathlets.org/mathlets/amplitude-and-phase-2nd-order-ii/}
{AMPLITUDE AND PHASE: SECOND ORDER II}

The input is the sinusoid $\cos (\omega t)$ and and system response is $x$.
Set $b=.5$ and $k=3$.
(Pro tip: click on the numbers above the sliders so that the pointer moves to the exact slider value.)\\

\begin{enumerate}
\item Find the formula for the complex gain $G$ in terms of $\omega$.
  (Answer for $b=.5$ and $k=3$.) \\
  The complex gain is
  \begin{equation*}
    G(\omega) = \frac{Q(i \omega)}{P(i \omega)} = \frac{0.5i \omega}{(i \omega)^2 + 0.5 i \omega + 3}
    = \frac{0.5i \omega}{3 - \omega ^2  + 0.5 i \omega }
  \end{equation*}
\item Use the complex gain $G$ to determine what happens to
  $g$ when $\omega$ is close to zero. (Answer for $b=.5$ and $k=3$.) \\
  When $\omega$ tends to zero,
  \begin{equation*}
    G(\omega ) = \frac{.5\omega i}{3-\omega ^2+.5 \omega i}
    \approx \frac{.5\omega i}{3} \longrightarrow 0
  \end{equation*}
  Therefore $g = |G|$ also also tends to zero as $\omega \rightarrow 0$\\

  What happens when $\omega$ is large? (Answer for $b=.5$ and $k=3$.)\\
  When $\omega$ is large,
  \begin{equation*}
    G(\omega ) = \frac{.5\omega i}{3-\omega ^2+.5 \omega i}
    \approx \frac{.5\omega i}{-\omega ^2} \longrightarrow 0.
  \end{equation*}
  Therefore $g=|G|$ also tends to zero as $\omega \rightarrow \infty$.
  Since $G$ and hence $g$ is not identically zero, we expect that between $0$ and $\infty$,
  there is some resonant frequency $\omega _r$ where $g$ obtains a maximum value.   
\end{enumerate}

\begin{exercise}
  Mathlet activity 2
\end{exercise}

The mathlet below shows the steady state response of
a spring-mass-dashpot system in series being driven
sinusoidally through the spring by a piston at the top.
The mass in this system is $1kg$. The equation modeling this system is
\begin{equation*}
  \ddot x + b\dot x + k x = k \cos \omega t.
\end{equation*}

\href{http://mathlets.org/mathlets/amplitude-and-phase-2nd-order/}
{AMPLITUDE AND PHASE: SECOND ORDER I}

The input is the sinusoid $\cos ⁡(\omega t)$ and system response is $x$.
Set $b=1.5$ and $k=1$.
(Pro tip : click on the numbers above the sliders so that the pointer moves to the exact slider value.)

\begin{enumerate}
\item Find the formula for the complex gain $G$ in terms of $\omega$.
  (Answer for $b=1.5$ and $k=1$.) \\
  The complex gain is
  \begin{equation*}
    G(\omega) = \frac{Q(i \omega)}{P(i \omega)} = \frac{1}{(i \omega)^2 + 1.5 i \omega + 1}
    = \frac{1}{1 - \omega ^2  + 1.5 i \omega }
  \end{equation*}
\item Use the complex gain $G$ to determine what happens
  to $g$ when $\omega$ is close to zero. (Answer for $b=1.5$ and $k=1$.) \\
  When $\omega$ tends to zero,
  \begin{equation*}
    G(\omega ) = \frac{1}{1-\omega ^2+1.5 \omega i} \rightarrow \frac{1}{1} =1.
  \end{equation*}
  Therefore $g=|G|$ also tends to $1$ as $\omega \rightarrow 0$.\\

  What happens to $g$ when $\omega$ is large?\\
  When $\omega$ is large,
  \begin{equation*}
    G(\omega ) = \frac{1}{1-\omega ^2+1.5 \omega i} \approx \frac{1}{-\omega ^2} \rightarrow 0.
  \end{equation*}
  Therefore $g=|G|$ also tends to zero as $\omega \rightarrow \infty$.
  It is not clear whether there is a resonant frequency or not.
  Using the Bode plot in the mathlet,
  we see that g is monotonically decreasing and this system has no resonance.  
\end{enumerate}
\clearpage

\subsubsection{Series RLC circuits}

Resonance is a phenomenon that is very important in the design of electrical circuits.
So we will model an RLC circuit in series.
Then we will explore how resonance enables different elements in the circuit act as low-pass filters, high-pass filters, or mid-pass filters– selectively allowing certain
driving frequencies to pass through while others diminish.\\

\paragraph{Introduction and modeling}
Our goal today is to set up differential equations
for an electrical circuit and to explore how different system
measurements or outputs give rise to different responses.
We'll analyze one-loop circuits and introduce the principles
that eventually work for more complicated circuits as well.
Here, I have a one-loop circuit consisting
of a single resistor with resistance $R$,
a single inductor with inductance $L$,
and a capacitor with capacitance $C$.
Note that the letter $L$ is given to the inductance
because the letter $I$ is reserved for current.
$L$ is in honor of physicist Heinrich Lenz.
Let's dig into RLC circuits now.\\


We will model the system using the five-step process.

\begin{enumerate}[label=Step.\arabic*]
\item To draw a diagram of the system.

  \begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{image-series_RLC}
    \caption{Series RLC cricuit}
  \end{figure}

  We'll start with the power source, which is denoted
  by a circle with a wiggle.
  And we'll connect our components by wires,
  denoted by straight lines.
  The first component in our system
  will be the resistor, drawn as a zigzag.
  The second component is our inductor,
  which is denoted by a coil.
  And the final component is a capacitor,
  denoted by parallel segments.
  We then connected it back to the power source.
  And we have here our single-loop circuit.
  Since all the components are in series one after the other,
  we call this a series circuit.
  So these are RLC circuits in series.
  So the power source provides a voltage V.
  The resistor has a resistance R. The inductor has
  an inductance L. And the capacitor has a capacitance C.

\item To identify all the variables and give the corresponding symbols. \\

  So the first variable will be the input voltage, which
  will be a function of time.
  So $V$ is $V(t)$, a function of time.
  The second variable is the current
  that goes through the system.
  So we'll denote the current by $I(t)$, also a function of time.
  And we'll denote positive current
  as current that flows clockwise in this diagram.
  Since this is a series circuit, the current
  through all the components is the same.
  The other three parts that we can measure of the system
  are the voltage drops across each of these three components.
  So we have $V_R$ to be the voltage drop across the resistor.
  \begin{align*}
    &V _R : \qquad \text{The voltage drop across the resistor,} \\
    &V _L : \qquad \text{The voltage drop across the inductor,} \\
    &V _C : \qquad \text{The voltage drop across the capacitor.} \\
  \end{align*}
  And these are all the variables that we
  can measure in this system. \\
  So each of these components has an associated law that relates the voltage drop to current.
  So the associated law for
  \begin{align*}
    & V_R(t) = R I(t),  \\
    & V_L(t) = L \dot I (t),  \\
    & \dot V _C(t) = \frac{1}{C} I (t). \\
  \end{align*}
  So note that $R,\, L,\, $ and $C$ are all constants.
  So these are linear relations between voltage drop and current.
  And these laws are actually a pretty big deal
  because it took generations of physicists
  to come up with them.
  And although they're not perfect,
  they serve as a great model that works for a wide range of circuits.
  So these are very important laws in physics.
  And then other thing that the circuit obeys is Kirchhoff's voltage law. \\  
  So Kirchhoff's voltage law says that the voltage gain
  from the power source is equal to the sum
  of all the voltage drops across the circuit.
  So we have
  \begin{equation*}
    V = V _R + V _L + V _C.
  \end{equation*}
  And here, since we want to rewrite everything eventually
  as a single equation, we have to rewrite things
  in terms of time derivatives because we have $V _C$ dot showing up above.
  So a natural next step to take is  to differentiate Kirchhoff's law.
  So we would get
  \begin{equation*}
    \dot V = \dot V _R + \dot V _L + \dot V _C.
  \end{equation*}
  This way, we can use the relations that we have
  and plug them into the time derivative
  of Kirchhoff's voltage law.

\item To declare what's the input and what's the system response of this system.\\
  So if we have an AM radio, for example,
  we would have the \textit{input} being the voltage that
  is received through the radio waves hitting the antenna.
  And that would be seen here in the \textit{power source} of the circuit.
  An \textit{output} that we would be interested in-- so the system
  response we would be interested in--
  would be the \textit{voltage drop across the resistor},
  as that signifies the output that we
  get through our headphones in an AM radio.
  So in our case, we will look at the system response
  of the \emph{voltage drop across the resistor}.
  We could have chosen any of the voltage drops or even
  the current as our system response.
  But because we're interested in analyzing an AM radio,
  we'll take $V_R$ as our system response.\\
\item  Rewrite things  in terms of our variable of interest--
  in terms of our system response.\\
  So we want to rewrite this associated laws in terms of $V _R$.
  So in the equation $ V_R(t) = R I(t)$, I want to rewrite
  \begin{equation*}
    I(t) = \frac{V _R (t)}{R}. 
  \end{equation*}
  In the equation $V _L(t) = L \dot I (t)$,
  I know that I need the time derivative of the current.
  So I'll need to differentiate this part.
  And the only thing that's a function of time is $V _R$.
  So we would get
  \begin{equation*}
    V _L (t) = \frac{L}{R} \dot V _R (t)
  \end{equation*}
  And finally, in our last equation $\dot V _C = \frac{1}{C} I(t)$,
  I have that
  \begin{equation*}
    \dot V _C = \frac{1}{C} \frac{V _R(t)}{R}
  \end{equation*}
  Now we have all of our variables as functions of the system response.

  \item In order to get a single differential equation
  for $V _R$, the voltage drop across the resistor,
  is to plug in all of these expressions into Kirchhoff's voltage law.
  So we have
  \begin{equation*}
    \dot V = \dot V _R + \frac{L}{R} \ddot V _R + \frac{1}{CR} V _R
  \end{equation*}
  So over here, we have a single differential equation
  with our input in one side and our system
  responds in the other.
  So one side only depends on the system response.
  And one side only depends on the input.\\

  \item To rewrite so-- as we generally
  do with the system response on the left-hand side
  and with the input on the right-hand side.
  For simplicity, I will multiply both sides by $R$.
  That way, each component will only have a single parameter,
  a single constant multiplying it.
  And we'll see that in a second.
  And now reorder such that the higher order derivatives
  appear first.
  So multiplying by $R$ and putting first the highest order
  derivative, we would have
  \begin{equation*}
    L \ddot V _R + R \dot V _R + \frac{1}{C} V _R = R \dot V
  \end{equation*}
  Now we have system response on the left-hand side, input
  in the right-hand side, and the coefficients of each term
  is a single constant-- a different constant, but a single one.
  So this is the differential equation for the system
  response for a given input.
\end{enumerate}

We can compare this equation to the mass-dashpot-spring system.
\begin{align*}
  &m \ddot x + b \dot x + k x = b \dot y \qquad \text{Mass-dashpot-spring system,} \\
  &L \ddot V _R + R \dot V _R + \frac{1}{C} V _R = R \dot V
    \qquad \text{RLC series system.} \\
\end{align*}
So we can match each term.
And they all look the same.
So these two equations have the exact same form,
meaning that their solutions are of the same form.
And that's a very important result--
that RLC circuits can be modeled by the same equations
that some physical systems are modeled.
So what if we had chosen other system responses?
What if we look at the system response across the inductor?
And what about the system response across the capacitor?
What would be the differential equations for each of these system responses? \\

A very simple passive AM radio receiver may be modeled by the following circuit.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\textwidth]{image-series_RLC}
  \caption{Series RLC cricuit}
\end{figure}

The power source at left is the antenna, being driven by radio waves.
The resistor at top is a speaker.
The other components are a capacitor (at bottom) and an inductance coil (at right). \\

We will model this circuit using the same five-step process as before.

\begin{enumerate}
\item \textbf{\color{blue} Draw a diagram of the system.} We've already done Step 1!
\item \textbf{\color{blue} Identify and give symbols for the parameters and variables of the system. }
  The diagram shows symbols for four standard electronic components:
  \begin{align*}
    &{\color{blue} R} : \qquad \text{resistance of the resistor}\, (ohms) \\
    &{\color{blue} L} : \qquad \text{inductance of the inductor}\, (henries) \\
    &{\color{blue} C} : \qquad \text{capacitance of the capacitor}\, (farads) \\
    &{\color{blue} V} : \qquad \text{voltage source}\, (volts)
  \end{align*}
  The quantities $R,\, L,\, C$ are constants while the voltage source $V$ is a function of time. \\

  Next, to understand the diagram above, we need to define an orientation of the circuit;
  say that current flows counterclockwise.
  Since it's a series circuit, the current through any of the wires is the same; write
  ${\color{blue}I(t)}$ for it.
  Then we can say that the power source, at left,
  produces a voltage \emph{increase} of ${\color{blue}V(t)}$ volts at time $t$.
  This voltage increase may vary with time, and may be negative as well as positive.
  In fact we'll be especially interested in the case in which it is sinusoidal! \\

  These are related by \emph{\color{blue} Kirchhoff's voltage law} :
  The voltage gain across the power source must equal
  the sum of the voltage drops across the other components:
  \begin{equation*}
    V=V_ L+V_ R+V_ C\, .
  \end{equation*}
  
\item \emph{\color{blue}Declare the input signal and the system response.}
  We will declare the voltage increase $V(t)$ produced by the power source as the input signal.
  For system response, we are interested in the loudness of the speaker,
  which is proportional to the voltage drop across the resistor.
  So we declare $V _R$ to be the system response. \\

  This means that we want to set up a differential equation relating $V(t)$ to $V _R (t)$.

\item \emph{\color{blue}Write down a differential equation relating the input signal and the system response,
    using Newton's ``$F=ma$" in the mechanical case or Kirchhoff's laws in the electrical case.}
  Because $\dot V _C$ appears in the definition of a capacitor,
  it is natural to differentiate Kirchhoff's voltage law, and rewrite in terms of $I$;
  \begin{equation*}
    \dot V=\dot V_ L+\dot V_ R+\dot V_ C=L\ddot I+R\dot I+(1/C)I\, .
  \end{equation*}

  To make this into an equation relating the input signal $V$ to the system response $V _R, \,$
  we just have to remember that $V _R=RI$. So multiply through by $R$ and make this substitution,
  along with its consequences $\dot V _R=R \dot I$ and $\ddot V _R= R \ddot I$:
  \begin{equation*}
    R\dot V=L\ddot V_ R+R\dot V_ R+(1/C)V_ R\, .
  \end{equation*}

  We're done. But before we discuss consequences, recall the equation describing
  the spring/mass/dashpot system driven through the spring:
  \begin{equation*}
    m\ddot x+b\dot x+kx=b\dot y\, .
  \end{equation*}

  \clearpage
  
  These two equations are formally identical in the way they relate input and system response.
  This reflects a rough parallel between mechanical and electrical systems, in which

  \begin{table}[ht!]
    \centering
    \begin{tabular}{|l|l|l|l|}
      \hline
      \multicolumn{2}{|l|}{Mechanical} & \multicolumn{2}{l|}{Electrical} \\ \hline
      displacement & $x,\, y$ & Voltage drop, gain& $V _R,=, v$\\ \hline
      mass & $m$ & Inductance & $L$ \\ \hline
      damping constant & $b$ & Resistance& $R$ \\ \hline
      spring constant  & $k$ & 1/capacitance & $1/C$ \\ \hline
    \end{tabular}
  \end{table}
  Similarly, a harmonic oscillator (undamped) is analogous to a series LC circuit (no resistor).
\end{enumerate}

\begin{exercise}
  DEs for voltage drops across inductor and capacitor
\end{exercise}

Write down the differential equation for
the voltage drop across the inductor $V _L$ by by entering the coefficients of
$\dot V _L, \,  V _L,\,$ and the differential operator acting on $V$ on the right hand side of the DE.\\
By Kirchhoff's voltage law
\begin{equation*}
  V=V_ L+V_ R+V_ C\, .
\end{equation*}
In series circuit, the current through the components is same.
So, rewrite the equation
\begin{equation*}
  V= L \dot I + R I + \frac{1}{C} \int I.
\end{equation*}
The current through inductor is
\begin{align*}
  L \dot I &= V _L \\
  \dot I &= \frac{1}{L} V _L \\
  \int \dot I &= \frac{1}{L} \int V _L \\
  I &= \frac{1}{L} \int V _L
\end{align*}
Substitute $\frac{1}{L} \int V _L$ then
\begin{align*}
  V &= L \frac{1}{L}  (\int V _L)^{\prime} + R \frac{1}{L} \int V _L +
      \frac{1}{L} \frac{1}{C} \int \int V _L \\
  V &= V _L + \frac{R}{L} \int V _L + \frac{1}{CL}  \int \int V _L \\
  \dot V &=  \dot V _L + \frac{R}{L} V _L + \frac{1}{CL}  \int V _L \\
  \ddot V &=  \ddot V _L + \frac{R}{L} \dot V _L + \frac{1}{CL} V _L \\
  L \ddot V &=  L \ddot V _L + R \dot V _L + \frac{1}{C} V _L 
\end{align*}

The DE for the the voltage drop across the inductor is
\begin{equation*}
  \displaystyle  L{\color{blue}{\ddot{V}_ L}} +
  R{\color{blue}{\dot{V}_ L}} _+\frac{1}{C} {\color{blue}{V_ L}}
  \displaystyle =
  \displaystyle  L{\color{orange}{\ddot V}}
\end{equation*}

\textbf{Note:} This is analogous to the DE that describe the spring-mass-dashpot system with a
driving force $F= m \ddot y$ on the mass:
\begin{equation*}
  \displaystyle  \displaystyle m\ddot{x}+b\dot{x}+kx
  \displaystyle = \displaystyle \displaystyle  m\ddot{y}.  
\end{equation*}

Write down the differential equation for the voltage drop across the capacitor
by entering the coefficients and the right hand side below: \\

The DE for the the voltage drop across the capacitor is
\begin{equation*}
  \displaystyle  \displaystyle L{\color{blue}{\ddot{V}_ C}}
  +R{\color{blue}{\dot{V}_ C}} _+\frac{1}{C} {\color{blue}{V_ C}}
  \displaystyle =
  \displaystyle \frac{1}{C} {\color{orange}{V}}
\end{equation*}

\textbf{Note:} This is analogous to the DE that describe the spring-mass-dashpot
system driven through the spring:
\begin{equation*}
  \displaystyle  \displaystyle m\ddot{x}+b\dot{x}+kx
  \displaystyle =
  \displaystyle  ky.
\end{equation*}

\clearpage
\subsubsection{Gain for different system responses}

\paragraph{Complex gain for the different responses}
You've now found the differential equation
for the voltage drop across the three components in an RLC
circuit in series.
\begin{align*}
  L \ddot V _R + R \dot V _R + \frac{1}{C} V _R &= R \dot V \\
  L \ddot V _L + R \dot V _L + \frac{1}{C} V _L &= L \ddot V \\
  L \ddot V _C + R \dot V _C + \frac{1}{C} V _C &= \frac{1}{C} V  
\end{align*}

Note that the left-hand side of these three equations
is of the same form.
So they have the same coefficients
and the same derivatives acting on the same places.
But the way that the input enters into the right-hand side
is different, depending on the system response that we pick.
So if we look at a purely sinusoidal input, such as
$V = \cos (\omega t)$, we can ask what
are the system responses as omega changes?

\begin{itemize}
\item What happens if omega is small, if we're driving at low frequencies?
\item What happens when omega is big?
\item Is there a value of omega that gives me a maximal response? 
\end{itemize}

And we'll see that the answers are different,
depending on the system response that we look at. \\


So one way to get the answer to see
what happens as we change$\omega$ is to calculate the gain, what we call little $g(\omega)$.
And that's defined as the $|G(\omega)|$,where $G$ is a complex number.
So in the case of a problem where we have
so if we have an equation of the type 
\begin{equation*}
  P(D)x = Q(D)y 
\end{equation*}
and this is the case here, because we have a polynomial acting on our system responses.
And then, on the right-hand side here, we have another polynomial acting on the input, which
is what we have in these three right-hand sides.\\
So if we have a system like this, which we do,
we can compute $G(\omega)$, which
is defined to be $\frac{Q(i \omega)}{P(i \omega)}$.
So what that means is that we need
to know what the polynomial $Q(D)$ is for each of these system responses.
And we need to know what $P(D)$, again, for each of these differential equations.\\


So let's do that.
Like I said, before, these three equations
have the same left-hand side.
Meaning that, the $P(D)$ or the operator
\begin{equation*}
  P(D) = LD^2 + RD + \frac{1}{C}\,  \mathds{1}. 
\end{equation*}
that it's being acted on to these system responses is the same.
I'll add the identity operator $\mathds{1}$, just to make this an operator.
And this just means I'm multiplying my system response by a constant.
And in order to calculate the complex gain,
we need to evaluate $P(i \omega)$.
So we'll plug that into this polynomial.
\begin{equation*}
  P(i \omega) = \frac{1}{C} - L \omega ^2 + iR \omega. 
\end{equation*}
So over here, we have computed the first part.
And this is actually the same for all these three equations.
Now the second part in order to calculate the gain,
the complex gain, actually, is to find $Q(D)$.
\begin{align*}
  &Q _R(i \omega) = RD = iR \omega \\
  &Q _L(i \omega) = LD^2 = -L \omega^2 \\
  &Q _R(i \omega) = \frac{1}{C}\, \mathds{1} = \frac{1}{C}
\end{align*}
Now we have all the ingredients to calculate the complex gain.
We have all of the $Q(D)$ evaluated at $i \omega$.
And we have $P(i \omega)$, which is the same for all
of the three components.
\begin{align*}
  &G _R(\omega) = \frac{Q(i \omega)}{P(i \omega)}
    = \frac{iR \omega}{\frac{1}{C} - L \omega ^2 + iR \omega. } \\
  &G _L(\omega) = \frac{Q(i \omega)}{P(i \omega)}
    = \frac{-L \omega ^2}{\frac{1}{C} - L \omega ^2 + iR \omega. } \\
  &G _C(\omega) = \frac{Q(i \omega)}{P(i \omega)}
    = \frac{\frac{1}{C}}{\frac{1}{C} - L \omega ^2 + iR \omega}.    
\end{align*}

Recall the DE for the system response $V _R$ and system input $V$ is
\begin{align*}
  \displaystyle  P(D) V_ R\, =\,  Q(D) V,\qquad \text {where }\, \,
  &\displaystyle  P(D)\, =\, L D^2 +R D+\frac{1}{C} \\
  &\displaystyle Q(D)\, =\,  RD.
\end{align*}

(Recall $D$ is the differential operator $D=\frac{d}{dt}$. ) The complex gain for $V _R$ is therefore
\begin{equation*}
  \displaystyle  G_ R(\omega )
  \displaystyle =
  \displaystyle \frac{Q(i\omega )}{P(i\omega )}
  \displaystyle =
  \displaystyle \frac{iR\omega }{\left(\frac{1}{C}-L\omega ^2\right)+iR\omega }.
\end{equation*}

\begin{exercise}
  Complex gain for the voltage drops across inductor and capacitor
\end{exercise}

Find the complex gain $G _L(\omega)$ and $G _C(\omega)$ for
the system responses $V _L$ and $V_C$ respectively.
(Enter in terms of $L,\, C,\, R,$ and the input angular frequency $\omega$.)

The $G _L$ and $G _C$ are
\begin{align*}
    &G _L(\omega) ) =  \frac{-L \omega ^2}{\frac{1}{C} - L \omega ^2 + iR \omega. } \\
    &G _C(\omega) =  \frac{\frac{1}{C}}{\frac{1}{C} - L \omega ^2 + iR \omega}.    
\end{align*}

\begin{exercise}
  Sum of the three complex gains
\end{exercise}
What is the sum of the complex gain of the 3 responses as a function of $\omega$?
That is, find the sum
\begin{equation*}
  G_ R (\omega )+G_ L(\omega )+G_ C(\omega ).
\end{equation*}

At all frequencies $\omega$,
\begin{equation*}
  G_ R + G_ L + G_ C\, =\, 1
\end{equation*}

\emph{Note:} The equation reflects Kirchhoff voltage law:
\begin{equation*}
  V_ R+V_ L+V_ C=V
\end{equation*}

\clearpage


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "NoteForDifferentialEquation"
%%% End:
